"""
ì„¸ë§ˆí¬ì–´ ì „ìš© ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ê¸° (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)
ê²°ê³¼ íŒŒì¼ì˜ contention_group_size, contention_user_ids ì»¬ëŸ¼ í™œìš©
"""
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
import warnings
import platform
import matplotlib.font_manager as fm
import argparse
warnings.filterwarnings('ignore')

def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì •"""
    system = platform.system()
    font_name = {'Windows': 'Malgun Gothic', 'Darwin': 'AppleGothic'}.get(system, 'DejaVu Sans')
    if system == 'Linux':
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        font_name = next((f for f in ['NanumGothic', 'DejaVu Sans'] if f in available_fonts), 'sans-serif')
    plt.rcParams['font.family'] = font_name
    plt.rcParams['axes.unicode_minus'] = False

# í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤í–‰
setup_korean_font()

class SemaphoreConcurrencyAnalyzer:
    def __init__(self, room_number=None, preprocessor_file=None, result_file=None, output_dir=None):
        """
        ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            room_number (int): ë¶„ì„í•  íŠ¹ì • ë°© ë²ˆí˜¸ (ê°„íŠ¸ ì°¨íŠ¸ëŠ” ë‹¨ì¼ë°©ë§Œ ì§€ì›)
            preprocessor_file (str): ì „ì²˜ë¦¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (preprocessor_semaphore.csv)
            result_file (str): ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (semaphore_analysis_result.csv)
            output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.room_number = room_number
        self.preprocessor_file = preprocessor_file
        self.result_file = result_file
        self.output_dir = output_dir
        
        # ë°ì´í„° ì €ì¥ìš© ë³€ìˆ˜
        self.df_preprocessor = None
        self.df_result = None
        
        # ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ ë¶„ì„ ê²°ê³¼ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)
        self.total_requests = 0
        self.concurrent_executions = 0
        self.max_concurrent_level = 0
        
        # ì‹œê°„ ë²”ìœ„ ì •ë³´
        self.global_time_start = None
        self.global_time_end = None
    
    def load_data(self):
        """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì„¸ë§ˆí¬ì–´ ë°ì´í„° ì „ì²˜ë¦¬"""
        try:
            # 1. ì „ì²˜ë¦¬ íŒŒì¼ ë¡œë“œ (ì°¨íŠ¸ìš© - preprocessor_semaphore.csv)
            self.df_preprocessor = pd.read_csv(self.preprocessor_file)
            print(f"âœ… ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(self.df_preprocessor)}ê±´")
            
            # 2. ê²°ê³¼ íŒŒì¼ ë¡œë“œ (ë¶„ì„ìš© - semaphore_analysis_result.csv)
            self.df_result = pd.read_csv(self.result_file)
            print(f"âœ… ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(self.df_result)}ê±´")
            
        except FileNotFoundError as e:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return False
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
            return False
        
        # 3. ê²°ê³¼ íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_result_columns = ['contention_group_size', 'contention_user_ids']
        missing_columns = [col for col in required_result_columns if col not in self.df_result.columns]
        
        if missing_columns:
            print(f"âŒ ê²°ê³¼ íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
            return False
        else:
            print("âœ… ê²°ê³¼ íŒŒì¼ contention ì»¬ëŸ¼ í™•ì¸ ì™„ë£Œ")
        
        # 4. ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ë°ì´í„° í™•ì¸
        nano_columns = ['true_critical_section_nanoTime_start', 'true_critical_section_nanoTime_end']
        has_nano = all(col in self.df_preprocessor.columns for col in nano_columns)
        
        if has_nano:
            print("âœ… ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ë°ì´í„° í™•ì¸ ì™„ë£Œ")
        else:
            print("âš ï¸ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ë°ì´í„° ì—†ìŒ - ì°¨íŠ¸ ìƒì„± ì œí•œë¨")
        
        # 5. ë°© ë²ˆí˜¸ë¡œ í•„í„°ë§ (ì§€ì •ëœ ê²½ìš°ë§Œ)
        if self.room_number is not None:
            before_filter = len(self.df_preprocessor)
            self.df_preprocessor = self.df_preprocessor[self.df_preprocessor['roomNumber'] == self.room_number]
            print(f"âœ… ì „ì²˜ë¦¬ ë°ì´í„° ë°© {self.room_number} í•„í„°ë§: {before_filter} â†’ {len(self.df_preprocessor)}ê±´")
            
            before_filter_result = len(self.df_result)
            self.df_result = self.df_result[self.df_result['roomNumber'] == self.room_number]
            print(f"âœ… ê²°ê³¼ ë°ì´í„° ë°© {self.room_number} í•„í„°ë§: {before_filter_result} â†’ {len(self.df_result)}ê±´")
        
        # 6. ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± í†µê³„ ê³„ì‚° (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)
        self._calculate_concurrency_statistics()
        
        return True
    
    def _calculate_concurrency_statistics(self):
        """ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± í†µê³„ ê³„ì‚° (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)"""
        self.total_requests = len(self.df_result)
        
        # ê²°ê³¼ íŒŒì¼ì˜ contention_group_size ì»¬ëŸ¼ì—ì„œ ì§ì ‘ í†µê³„ ê³„ì‚°
        group_sizes = self.df_result['contention_group_size']
        
        # ë™ì‹œ ì‹¤í–‰ ë°œìƒ ê±´ìˆ˜ (group_size >= 2)
        self.concurrent_executions = len(group_sizes[group_sizes >= 2])
        
        # ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜ì¤€
        self.max_concurrent_level = group_sizes.max()
        
        print(f"ğŸ“Š ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± í†µê³„ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜):")
        print(f"   ì´ permit ìš”ì²­: {self.total_requests}ê±´")
        print(f"   ë™ì‹œ ì‹¤í–‰ ë°œìƒ: {self.concurrent_executions}ê±´")
        print(f"   ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜ì¤€: {self.max_concurrent_level}ê°œ ìŠ¤ë ˆë“œ")
        
        # ë™ì‹œì„± ë¶„í¬ ì¶œë ¥
        size_distribution = group_sizes.value_counts().sort_index()
        print(f"   ë™ì‹œì„± ë¶„í¬:")
        for size, count in size_distribution.items():
            print(f"     í¬ê¸° {size}: {count}ê±´")
    
    def create_output_folders(self):
        """ì¶œë ¥ í´ë” ìƒì„±"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {self.output_dir}")
        else:
            print(f"âœ… ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸: {self.output_dir}")
    
    def calculate_global_time_range(self):
        """ì „ì²´ ì‹œê°„ ë²”ìœ„ ê³„ì‚°"""
        if ('true_critical_section_nanoTime_start' not in self.df_preprocessor.columns or
            'true_critical_section_nanoTime_end' not in self.df_preprocessor.columns):
            print("âŒ ë‚˜ë…¸ì´ˆ ë°ì´í„° ì—†ìŒ - ì‹œê°„ ë²”ìœ„ ê³„ì‚° ë¶ˆê°€")
            return False
        
        # ìœ íš¨í•œ ì‹œê°„ ë°ì´í„°ë§Œ í•„í„°ë§
        valid_data = self.df_preprocessor[
            self.df_preprocessor['true_critical_section_nanoTime_start'].notna() & 
            self.df_preprocessor['true_critical_section_nanoTime_end'].notna()
        ]
        
        if valid_data.empty:
            print("âŒ ìœ íš¨í•œ ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŒ")
            return False
        
        self.global_time_start = valid_data['true_critical_section_nanoTime_start'].min()
        self.global_time_end = valid_data['true_critical_section_nanoTime_end'].max()
        
        print(f"ğŸŒ ì „ì²´ ì‹œê°„ ë²”ìœ„:")
        print(f"   ì‹œì‘: {self.global_time_start} ë‚˜ë…¸ì´ˆ")
        print(f"   ì¢…ë£Œ: {self.global_time_end} ë‚˜ë…¸ì´ˆ")
        print(f"   ë²”ìœ„: {self.global_time_end - self.global_time_start} ë‚˜ë…¸ì´ˆ")
        
        return True
    
    def determine_time_unit(self, time_range):
        """ì‹œê°„ ë²”ìœ„ì— ë”°ë¥¸ ìµœì  ë‹¨ìœ„ ê²°ì •"""
        if time_range < 1000:
            return 'ns', 1, 'ns'
        elif time_range < 1000000:
            return 'Î¼s', 1000, 'Î¼s'
        elif time_range < 1000000000:
            return 'ms', 1000000, 'ms'
        else:
            return 's', 1000000000, 's'
    
    def format_time_with_unit(self, nano_time, divisor, unit):
        """ì§€ì •ëœ ë‹¨ìœ„ë¡œ ì‹œê°„ ë³€í™˜"""
        if unit == 'ns':
            return f"{nano_time:.0f}{unit}"
        elif unit == 'Î¼s':
            return f"{nano_time/divisor:.1f}{unit}"
        elif unit == 'ms':
            return f"{nano_time/divisor:.1f}{unit}"
        else:
            return f"{nano_time/divisor:.1f}{unit}"
    
    def create_semaphore_concurrency_gantt_chart(self):
        """ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê°„íŠ¸ ì°¨íŠ¸ ìƒì„±"""
        if self.room_number is None:
            print("âŒ ê°„íŠ¸ ì°¨íŠ¸ëŠ” ë‹¨ì¼ ë°©ë§Œ ì§€ì›í•©ë‹ˆë‹¤. --room_number ì˜µì…˜ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            return
        
        print(f"ğŸ“Š ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê°„íŠ¸ ì°¨íŠ¸ ìƒì„± (ë°© {self.room_number})")
        
        # ë‚˜ë…¸ì´ˆ ë°ì´í„° í™•ì¸
        if not self.calculate_global_time_range():
            return
        
        # ì‹œê°„ ë‹¨ìœ„ ê²°ì •
        time_range = self.global_time_end - self.global_time_start
        time_unit_name, time_divisor, time_unit_symbol = self.determine_time_unit(time_range)
        
        # binë³„ë¡œ ì°¨íŠ¸ ìƒì„±
        bins = sorted(self.df_preprocessor['bin'].unique())
        print(f"ë¶„ì„í•  bin ìˆ˜: {len(bins)}ê°œ")
        
        for bin_value in bins:
            print(f"ğŸ“Š bin {bin_value} ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ì°¨íŠ¸ ìƒì„±...")
            
            # í•´ë‹¹ bin ë°ì´í„° í•„í„°ë§ (ì „ì²˜ë¦¬ íŒŒì¼ê³¼ ê²°ê³¼ íŒŒì¼ ë§¤ì¹­)
            bin_preprocessor = self.df_preprocessor[self.df_preprocessor['bin'] == bin_value].copy()
            bin_result = self.df_result[self.df_result['bin'] == bin_value].copy()
            
            if bin_preprocessor.empty or bin_result.empty:
                print(f"âŒ bin {bin_value} ë°ì´í„° ì—†ìŒ")
                continue
            
            # ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬
            bin_preprocessor_sorted = bin_preprocessor.sort_values('true_critical_section_nanoTime_start')
            
            # ì°¨íŠ¸ ìƒì„±
            fig, ax = plt.subplots(1, 1, figsize=(20, 12))
            
            # ì„±ê³µì ì¸ ë™ì‹œ ì‹¤í–‰ ê°•ì¡° ì œëª©
            success_indicator = "âœ… CAS ê¸°ë°˜ ë™ì‹œ ì‹¤í–‰ ì„±ê³µ" if self.concurrent_executions > 0 else "ë‹¨ì¼ ì‹¤í–‰"
            title = f'ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ - ë°© {self.room_number}, bin {bin_value} ({success_indicator})'
            ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
            
            # ë™ì‹œ ì‹¤í–‰ ë ˆë²¨ ê³„ì‚° ë° ì‹œê°í™” (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)
            self._draw_concurrent_execution_bars(ax, bin_preprocessor_sorted, bin_result)
            
            # ë²”ë¡€ ì„¤ì •
            self._setup_legend(ax)
            
            # ì¶• ì„¤ì •
            self._setup_axes(ax, bin_preprocessor_sorted, time_range, time_divisor, time_unit_symbol)
            
            # í†µê³„ ì •ë³´ ë°•ìŠ¤ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)
            self._add_statistics_box(ax, bin_result)
            
            plt.tight_layout()
            
            # íŒŒì¼ ì €ì¥
            filename = f'semaphore_concurrency_pattern_room{self.room_number}_bin{bin_value}.png'
            chart_path = os.path.join(self.output_dir, filename)
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… bin {bin_value} ì°¨íŠ¸ ì €ì¥: {chart_path}")
    
    def _draw_concurrent_execution_bars(self, ax, preprocessor_data, result_data):
        """ë™ì‹œ ì‹¤í–‰ ë§‰ëŒ€ ê·¸ë¦¬ê¸° (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)"""
        user_ids = preprocessor_data['user_id'].unique()
        y_positions = {user_id: i for i, user_id in enumerate(user_ids)}
        
        # ê²°ê³¼ íŒŒì¼ì„ user_id ê¸°ì¤€ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        result_dict = {row['user_id']: row for _, row in result_data.iterrows()}
        
        for _, row in preprocessor_data.iterrows():
            user_id = row['user_id']
            start_time = row['true_critical_section_nanoTime_start']
            end_time = row['true_critical_section_nanoTime_end']
            duration = end_time - start_time
            
            y_pos = y_positions[user_id]
            
            # ê²°ê³¼ íŒŒì¼ì—ì„œ ë™ì‹œ ì‹¤í–‰ ë ˆë²¨ ê°€ì ¸ì˜¤ê¸°
            concurrent_level = 1  # ê¸°ë³¸ê°’
            if user_id in result_dict:
                concurrent_level = result_dict[user_id]['contention_group_size']
            
            # ìƒ‰ìƒê³¼ íˆ¬ëª…ë„ ê²°ì • (ë™ì‹œ ì‹¤í–‰ ìˆ˜ì¤€ì— ë”°ë¼)
            if concurrent_level == 1:
                color = 'lightblue'
                alpha = 0.6
                label_text = 'ë‹¨ë… ì‹¤í–‰ (permit 1ê°œ)'
            elif concurrent_level <= 3:
                color = 'blue'
                alpha = 0.7
                label_text = f'ë™ì‹œ ì‹¤í–‰ (permit {concurrent_level}ê°œ)'
            else:
                color = 'darkblue'
                alpha = 0.8
                label_text = f'ê³ ë„ ë™ì‹œ ì‹¤í–‰ (permit {concurrent_level}ê°œ)'
            
            # ë§‰ëŒ€ ê·¸ë¦¬ê¸°
            ax.barh(y_pos, duration, left=start_time, height=0.6,
                   alpha=alpha, color=color, edgecolor=color, linewidth=1)
            
            # ë™ì‹œ ì‹¤í–‰ ìˆ˜ì¤€ í‘œì‹œ
            ax.text(end_time, y_pos, f' {concurrent_level}', 
                   va='center', ha='left', fontsize=9, fontweight='bold')
        
        # Yì¶• ì„¤ì •
        ax.set_yticks(range(len(user_ids)))
        ax.set_yticklabels(user_ids, fontsize=10)
        ax.set_ylabel('ì‚¬ìš©ì ID (permit íšë“ ìˆœì„œ)', fontsize=12, fontweight='bold')
    
    def _setup_legend(self, ax):
        """ë²”ë¡€ ì„¤ì •"""
        # í†µí•©ëœ ë‹¨ì¼ ë²”ë¡€
        ax.barh([], [], height=0.6, alpha=0.7, color='blue', 
               label='ë™ì‹œ ì‹¤í–‰ êµ¬ê°„ í‘œì‹œ')
        
        ax.legend(fontsize=12, loc='upper right', framealpha=0.9)
    
    def _setup_axes(self, ax, data, time_range, time_divisor, time_unit_symbol):
        """ì¶• ì„¤ì •"""
        # Xì¶• ë²”ìœ„ ì„¤ì •
        ax.set_xlim(self.global_time_start, self.global_time_end)
        
        # Xì¶• í‹± ì„¤ì •
        num_ticks = 11
        tick_positions = np.linspace(self.global_time_start, self.global_time_end, num_ticks)
        
        tick_labels = []
        for pos in tick_positions:
            relative_time = pos - self.global_time_start
            tick_labels.append(self.format_time_with_unit(relative_time, time_divisor, time_unit_symbol))
        
        ax.set_xticks(tick_positions)
        ax.set_xticklabels(tick_labels, rotation=45)
        
        # Xì¶• ë ˆì´ë¸”
        time_range_display = self.format_time_with_unit(time_range, time_divisor, time_unit_symbol)
        ax.set_xlabel(f'ì„¸ë§ˆí¬ì–´ permit ì‹¤í–‰ ì‹œê°„ (ì´ ë²”ìœ„: {time_range_display})', 
                     fontsize=12, fontweight='bold')
        
        ax.grid(True, alpha=0.3)
    
    def _add_statistics_box(self, ax, result_data):
        """í†µê³„ ì •ë³´ ë°•ìŠ¤ ì¶”ê°€ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)"""
        bin_requests = len(result_data)
        bin_concurrent = len(result_data[result_data['join_result'] == 'SUCCESS'])
        
        # ë™ì‹œ ì‹¤í–‰ í†µê³„ (ê²°ê³¼ íŒŒì¼ì˜ contention_group_size ì‚¬ìš©)
        concurrent_permits = len(result_data[result_data['contention_group_size'] >= 2])
        
        stats_text = (f'bin ì´ ìš”ì²­: {bin_requests}ê±´\n'
                     f'permit ì„±ê³µ: {bin_concurrent}ê±´\n'
                     f'ë™ì‹œ permit ì‹¤í–‰: {concurrent_permits}ê±´')
        
        if bin_requests > 0:
            concurrency_rate = concurrent_permits / bin_requests * 100
            stats_text += f'\në™ì‹œì„± í™œìš©ë¥ : {concurrency_rate:.1f}%'
        
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', 
                bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.9))
    
    def generate_semaphore_concurrency_csv_report(self):
        """ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± íŒ¨í„´ CSV ë³´ê³ ì„œ ìƒì„±"""
        print("ğŸ“‹ ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± íŒ¨í„´ CSV ë³´ê³ ì„œ ìƒì„±")
        
        # ê²°ê³¼ ë°ì´í„° ì‚¬ìš© (contention ì •ë³´ í¬í•¨)
        all_data = self.df_result.copy()
        
        # ë°© ë²ˆí˜¸ í•„í„°ë§ (ì´ì¤‘ í™•ì¸)
        if self.room_number is not None:
            before_filter = len(all_data)
            all_data = all_data[all_data['roomNumber'] == self.room_number]
            print(f"ë°© {self.room_number} í•„í„°ë§: {before_filter} â†’ {len(all_data)}ê±´")
        
        # íŒŒì¼ëª… ìƒì„±
        if self.room_number:
            csv_filename = f'semaphore_concurrency_pattern_room{self.room_number}.csv'
        else:
            csv_filename = 'semaphore_concurrency_pattern_all_rooms.csv'
        
        csv_path = os.path.join(self.output_dir, csv_filename)
        
        # ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± íŠ¹í™” ì»¬ëŸ¼ (contention ì •ë³´ í¬í•¨)
        semaphore_columns = [
            'roomNumber', 'bin', 'room_entry_sequence', 'user_id',
            'prev_people', 'curr_people', 'max_people', 'join_result',
            'true_critical_section_nanoTime_start', 'true_critical_section_nanoTime_end',
            'contention_group_size', 'contention_user_ids'
        ]
        
        if all_data.empty:
            empty_df = pd.DataFrame(columns=semaphore_columns)
            empty_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"ë¹ˆ CSV íŒŒì¼ ìƒì„±: {csv_path}")
        else:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            available_columns = [col for col in semaphore_columns if col in all_data.columns]
            csv_df = all_data[available_columns].copy()
            
            # ëˆ„ë½ëœ ì»¬ëŸ¼ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì¶”ê°€
            for col in semaphore_columns:
                if col not in csv_df.columns:
                    csv_df[col] = ''
            
            # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
            csv_df = csv_df[semaphore_columns]
            
            # CSV ì €ì¥
            csv_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± íŒ¨í„´ CSV ë³´ê³ ì„œ: {len(csv_df)}ê±´ â†’ {csv_path}")
            print(f"contention_group_size, contention_user_ids ì»¬ëŸ¼ í¬í•¨ëœ ì™„ì „í•œ ë™ì‹œì„± ë°ì´í„°")
        
        return csv_path
    
    def run_analysis(self):
        """ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ ì‹œì‘ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)")
        print("ğŸ¯ ëª©í‘œ: CAS ê¸°ë°˜ permit ì‹œìŠ¤í…œì˜ ë™ì‹œ ì‹¤í–‰ íŠ¹ì„± ê´€ì°°")
        
        # 1. ë°ì´í„° ë¡œë”©
        if not self.load_data():
            print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
            return False
        
        # 2. ì¶œë ¥ í´ë” ìƒì„±
        self.create_output_folders()
        
        try:
            # 3. ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê°„íŠ¸ ì°¨íŠ¸ ìƒì„±
            self.create_semaphore_concurrency_gantt_chart()
            
            # 4. ë™ì‹œì„± íŒ¨í„´ CSV ë³´ê³ ì„œ ìƒì„±
            self.generate_semaphore_concurrency_csv_report()
            
            # 5. ìµœì¢… ê²°ê³¼ ìš”ì•½
            self._print_concurrency_summary()
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        return True
    
    def _print_concurrency_summary(self):
        """ë™ì‹œì„± ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        print("\n" + "="*60)
        print("ğŸ† ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ ìµœì¢… ê²°ê³¼ (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)")
        print("="*60)
        
        if self.max_concurrent_level > 1:
            print("âœ… CAS ê¸°ë°˜ ë™ì‹œ permit ì‹¤í–‰ ì„±ê³µ!")
            print(f"ğŸ”„ ìµœëŒ€ {self.max_concurrent_level}ê°œ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— permit íšë“")
            print("ğŸš€ ì„¸ë§ˆí¬ì–´ì˜ ë†’ì€ ë™ì‹œì„± ì²˜ë¦¬ ëŠ¥ë ¥ í™•ì¸")
        else:
            print("ğŸ“Š ë‹¨ì¼ permit ì‹¤í–‰ íŒ¨í„´ ê´€ì°°")
            print("ğŸ”’ ìˆœì°¨ì  permit ì²˜ë¦¬ë¡œ ì•ˆì •ì  ë™ì‘")
        
        print(f"\nğŸ“Š ìƒì„¸ í†µê³„:")
        print(f"   ì´ permit ìš”ì²­: {self.total_requests}ê±´")
        print(f"   ë™ì‹œ ì‹¤í–‰ ë°œìƒ: {self.concurrent_executions}ê±´")
        print(f"   ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜ì¤€: {self.max_concurrent_level}ê°œ ìŠ¤ë ˆë“œ")
        
        if self.total_requests > 0:
            concurrency_rate = (self.concurrent_executions / self.total_requests) * 100
            print(f"   ë™ì‹œì„± í™œìš©ë¥ : {concurrency_rate:.1f}%")
        
        print("\nğŸ¯ ê²°ë¡ : ê²°ê³¼ íŒŒì¼ì˜ contention ë°ì´í„°ë¥¼ í™œìš©í•œ ì •í™•í•œ ë™ì‹œ ì‹¤í–‰ ë¶„ì„ ì™„ë£Œ!")
        print("="*60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='ì„¸ë§ˆí¬ì–´ ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë¶„ì„ ë° ì‹œê°í™” (ê²°ê³¼ íŒŒì¼ ê¸°ë°˜)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì „ì²´ ë°© ë™ì‹œì„± íŒ¨í„´ ë¶„ì„
  python semaphore_concurrency_analyzer.py --preprocessor_file preprocessor_semaphore.csv --result_file semaphore_analysis_result.csv --output_dir output/
  
  # íŠ¹ì • ë°© ë™ì‹œì„± íŒ¨í„´ ë¶„ì„  
  python semaphore_concurrency_analyzer.py --room_number 1294 --preprocessor_file preprocessor_semaphore.csv --result_file semaphore_analysis_result.csv --output_dir output/
        """
    )
    
    parser.add_argument(
        '--room_number', 
        type=int, 
        help='ë¶„ì„í•  íŠ¹ì • ë°© ë²ˆí˜¸ (ê°„íŠ¸ ì°¨íŠ¸ ìƒì„±ì‹œ í•„ìˆ˜)'
    )
    
    parser.add_argument(
        '--preprocessor_file',
        type=str,
        required=True,
        help='ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ (preprocessor_semaphore.csv)'
    )
    
    parser.add_argument(
        '--result_file',
        type=str,
        required=True,
        help='ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ (semaphore_analysis_result.csv)'
    )
    
    parser.add_argument(
        '--output_dir',
        type=str,
        required=True,
        help='ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    args = parser.parse_args()
    
    # ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± ë¶„ì„ê¸° ìƒì„± ë° ì‹¤í–‰
    analyzer = SemaphoreConcurrencyAnalyzer(
        room_number=args.room_number,
        preprocessor_file=args.preprocessor_file,
        result_file=args.result_file,
        output_dir=args.output_dir
    )
    
    success = analyzer.run_analysis()
    
    if not success:
        print("âŒ ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± ë¶„ì„ ì‹¤íŒ¨")
        exit(1)
    else:
        print("ğŸ‰ ì„¸ë§ˆí¬ì–´ ë™ì‹œì„± ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
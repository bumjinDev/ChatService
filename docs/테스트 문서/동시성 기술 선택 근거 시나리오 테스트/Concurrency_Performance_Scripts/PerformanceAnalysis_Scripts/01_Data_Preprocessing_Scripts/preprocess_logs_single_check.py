#!/usr/bin/env python3
"""
ì„ê³„ ì˜ì—­ ì„±ëŠ¥ ì¸¡ì • ë¡œê·¸ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)

[ëª©ì ]
ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ì˜ ì„ê³„ ì˜ì—­(Critical Section) ì ‘ê·¼ ë¡œê·¸ë¥¼ íŒŒì‹±í•˜ì—¬
ì„±ëŠ¥ ë¶„ì„ìš© ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

[ì£¼ìš” ê¸°ëŠ¥]
1. ë¡œê·¸ íŒŒì¼ì—ì„œ 5ê°€ì§€ ì´ë²¤íŠ¸ ì¶”ì¶œ (WAITING_START, CRITICAL_ENTER, CRITICAL_LEAVE, INCREMENT_BEFORE, INCREMENT_AFTER)
2. ì‚¬ìš©ìë³„, ë°©ë³„ë¡œ ì´ë²¤íŠ¸ ê·¸ë£¹í™”
3. ë‹¨ìˆœí™”ëœ ì •ë ¬: waiting_start_nanoTime â†’ critical_enter_nanoTime
4. CSV ë° Excel í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
5. ì‚¬ìš©ì ì§€ì • ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì›

[ì´ë²¤íŠ¸ ì˜ë¯¸]
- WAITING_START: ì„ê³„ ì˜ì—­ ì§„ì… ëŒ€ê¸° ì‹œì‘
- CRITICAL_ENTER: ì„ê³„ ì˜ì—­ ì§„ì… ì„±ê³µ
- CRITICAL_LEAVE: ì„ê³„ ì˜ì—­ í‡´ì¥
- INCREMENT_BEFORE: ì¹´ìš´í„° ì¦ê°€ ì‘ì—… ì‹œì‘
- INCREMENT_AFTER: ì¹´ìš´í„° ì¦ê°€ ì‘ì—… ì™„ë£Œ

[ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° íŠ¹ì§•]
- PRE_CHECK_FAIL_OVER_CAPACITY ì´ë²¤íŠ¸ ì—†ìŒ (ë½ ì™¸ë¶€ ì‚¬ì „ í™•ì¸ ì—†ìŒ)
- 5ê°œ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬
- SUCCESS/FAIL_OVER_CAPACITY/UNKNOWN 3ê°€ì§€ ê²°ê³¼ë§Œ ë¶„ë¥˜

[ìˆ˜ì • ì‚¬í•­]
- PRE_CHECK_FAIL ê´€ë ¨ ëª¨ë“  ë¡œì§ ì œê±°
- 5ê°œ ì´ë²¤íŠ¸ ê¸°ë°˜ ë‹¨ìˆœ ì²˜ë¦¬
- waiting_start_nanoTime â†’ critical_enter_nanoTime ìˆœ ë‹¨ìˆœ ì •ë ¬
- pandas í˜¸í™˜ì„± ë¬¸ì œ ìˆ˜ì • (is_datetime64_tz_dtype â†’ pd.api.types.is_datetime64tz_dtype)
"""

import pandas as pd
import re
import os
import shutil
import argparse
import sys
from typing import Dict, List, Optional, Tuple, Any
from openpyxl import load_workbook

# ===== ìƒìˆ˜ ì •ì˜ =====
# íŒŒì¼ ê²½ë¡œ ìƒìˆ˜
LOG_FILE = 'ChatService.log'
NEW_LOG_PATH = r'E:\devSpace\ChatServiceTest\log\ChatService.log'

# ì´ë²¤íŠ¸ íƒ€ì… ìƒìˆ˜
EVENT_WAITING_START = 'WAITING_START'
EVENT_CRITICAL_ENTER = 'CRITICAL_ENTER'
EVENT_CRITICAL_LEAVE = 'CRITICAL_LEAVE'
EVENT_INCREMENT_BEFORE = 'INCREMENT_BEFORE'
EVENT_INCREMENT_AFTER = 'INCREMENT_AFTER'

# ê²°ê³¼ íƒ€ì… ìƒìˆ˜
RESULT_SUCCESS = 'SUCCESS'
RESULT_FAIL_CAPACITY = 'FAIL_OVER_CAPACITY'
RESULT_UNKNOWN = 'UNKNOWN'

# ë¶„ì„ êµ¬ê°„ ìˆ˜
BINS_COUNT = 10

# ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´
CRITICAL_PATTERN = re.compile(
    r'CRITICAL_SECTION_MARK tag=(?P<tag>WAITING_START|CRITICAL_ENTER|CRITICAL_LEAVE)'
    r' timestampIso=(?P<timestamp>[\w\-\:\.TZ]+)'
    r' event=(?P<event>\w+)'
    r'.* roomNumber=(?P<roomNumber>\d+)'
    r' userId=(?P<userId>[\w\-\_]+)'
    r'.* nanoTime=(?P<nanoTime>\d+)'
    r'.* epochNano=(?P<epochNano>\d+)'
)

INCREMENT_PATTERN = re.compile(
    r'timestampIso=(?P<timestamp>[\w\-\:\.TZ]+)'
    r' event=(?P<tag>INCREMENT_BEFORE|INCREMENT_AFTER)'
    r' roomNumber=(?P<roomNumber>\d+)'
    r' userId=(?P<userId>[\w\-\_]+)'
    r'.* epochNano=(?P<epochNano>\d+)'
    r'.* nanoTime=(?P<nanoTime>\d+)'
)


def test_critical_pattern():
    """CRITICAL_PATTERN ì •ê·œì‹ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    test_logs = [
        "CRITICAL_SECTION_MARK tag=WAITING_START timestampIso=2025-07-19T02:24:37.452142100Z event=PRE_JOIN_ATTEMPT className=RoomJoinServiceSynchronized methodName=confirmJoinRoom roomNumber=1203 userId=yhjj875 nanoTime=38434598060100 epochNano=1752891877453106700 threadId=247",
        "CRITICAL_SECTION_MARK tag=CRITICAL_ENTER timestampIso=2025-07-19T02:24:37.452142100Z event=CRITICAL_ENTER_EVENT className=RoomJoinServiceSynchronized methodName=confirmJoinRoom roomNumber=1203 userId=yhjj875 nanoTime=38434598060200 epochNano=1752891877453106800 threadId=247",
        "CRITICAL_SECTION_MARK tag=CRITICAL_LEAVE timestampIso=2025-07-19T02:24:37.452142100Z event=SUCCESS className=RoomJoinServiceSynchronized methodName=confirmJoinRoom roomNumber=1203 userId=yhjj875 nanoTime=38434598060300 epochNano=1752891877453106900 threadId=247"
    ]
    
    success_count = 0
    for i, test_log in enumerate(test_logs):
        match = CRITICAL_PATTERN.search(test_log)
        if match:
            result = match.groupdict()
            print(f"âœ… í…ŒìŠ¤íŠ¸ {i+1} ë§¤ì¹­ ì„±ê³µ: tag={result['tag']}, event={result['event']}")
            success_count += 1
        else:
            print(f"âŒ í…ŒìŠ¤íŠ¸ {i+1} ë§¤ì¹­ ì‹¤íŒ¨")
    
    return success_count == len(test_logs)


def replace_log_file() -> None:
    """
    ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì„ ìƒˆ ë¡œê·¸ íŒŒì¼ë¡œ êµì²´
    """
    if os.path.exists(LOG_FILE):
        os.remove(LOG_FILE)
    shutil.copy(NEW_LOG_PATH, LOG_FILE)
    print(f"ë¡œê·¸ íŒŒì¼ êµì²´ ì™„ë£Œ: {NEW_LOG_PATH} â†’ {LOG_FILE}")


def parse_log_line(line: str) -> Optional[Dict[str, Any]]:
    """
    ë¡œê·¸ ë¼ì¸ì„ íŒŒì‹±í•˜ì—¬ ì´ë²¤íŠ¸ ì •ë³´ ì¶”ì¶œ
    """
    # CRITICAL_SECTION_MARK íŒ¨í„´ ë§¤ì¹­
    match = CRITICAL_PATTERN.search(line)
    if match:
        data = match.groupdict()
        data['event_type'] = data['event']
        return data
    
    # INCREMENT ì´ë²¤íŠ¸ íŒ¨í„´ ë§¤ì¹­
    match = INCREMENT_PATTERN.search(line)
    if match:
        data = match.groupdict()
        data['event_type'] = None
        return data
    
    return None


def parse_five_events_clean(filepath: str, room_number: Optional[int] = None) -> pd.DataFrame:
    """
    ë¡œê·¸ íŒŒì¼ì—ì„œ 5ê°€ì§€ ì´ë²¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
    """
    records = []
    
    try:
        with open(filepath, encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                data = parse_log_line(line)
                
                if data:
                    # ë°© ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
                    data['roomNumber'] = int(data['roomNumber'])
                    
                    # ë‚˜ë…¸ì´ˆ ê°’ë“¤ì„ ë¬¸ìì—´ë¡œ ìœ ì§€
                    data['nanoTime'] = data['nanoTime']
                    data['epochNano'] = data['epochNano']
                    
                    # ë°© ë²ˆí˜¸ í•„í„°ë§
                    if room_number is None or data['roomNumber'] == room_number:
                        records.append(data)
    
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {filepath}")
        return pd.DataFrame()
    except Exception as e:
        print(f"ì˜¤ë¥˜: ë¡œê·¸ íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨ - {e}")
        return pd.DataFrame()
    
    return pd.DataFrame(records)


def process_user_events(user_id: str, user_data: pd.DataFrame) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ì‚¬ìš©ìì˜ ì´ë²¤íŠ¸ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ í”„ë¡œí•„ ìƒì„±
    """
    # nanoTime ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    user_data = user_data.sort_values(['nanoTime_num']).reset_index(drop=True)
    
    # ì´ë²¤íŠ¸ë³„ë¡œ ê·¸ë£¹í™”
    events = {}
    for _, row in user_data.iterrows():
        event_name = row['tag']
        events[event_name] = {
            'timestamp': row['timestamp'],
            'nanoTime': str(int(float(row['nanoTime']))),
            'epochNano': str(int(float(row['epochNano']))),
            'event_type': row.get('event_type')
        }
    
    # ê¸°ë³¸ í”„ë¡œí•„ ì •ë³´
    profile = {
        'user_id': user_id,
        'roomNumber': user_data.iloc[0]['roomNumber']
    }
    
    # ê° ì´ë²¤íŠ¸ë³„ ì •ë³´ ì¶”ê°€
    event_mappings = {
        EVENT_WAITING_START: 'waiting_start',
        EVENT_CRITICAL_ENTER: 'critical_enter',
        EVENT_CRITICAL_LEAVE: 'critical_leave',
        EVENT_INCREMENT_BEFORE: 'increment_before',
        EVENT_INCREMENT_AFTER: 'increment_after'
    }
    
    for event_tag, prefix in event_mappings.items():
        if event_tag in events:
            event_data = events[event_tag]
            profile.update({
                f'{prefix}_time': event_data['timestamp'],
                f'{prefix}_nanoTime': event_data['nanoTime'],
                f'{prefix}_epochNano': event_data['epochNano']
            })
            
            # event_typeì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
            if event_data['event_type'] is not None:
                profile[f'{prefix}_event_type'] = event_data['event_type']
    
    # join_result ì„¤ì • (CRITICAL_LEAVEì˜ event_type ê¸°ë°˜)
    if EVENT_CRITICAL_LEAVE in events:
        leave_type = events[EVENT_CRITICAL_LEAVE]['event_type']
        if leave_type == RESULT_SUCCESS:
            profile['join_result'] = RESULT_SUCCESS
        elif leave_type == RESULT_FAIL_CAPACITY:
            profile['join_result'] = RESULT_FAIL_CAPACITY
        else:
            profile['join_result'] = RESULT_UNKNOWN
    
    return profile


def assign_bins_and_sequence_after_first_sort(df: pd.DataFrame) -> pd.DataFrame:
    """
    1ì°¨ ì •ë ¬ ì§í›„ì— ì •ë ¬ëœ ìˆœì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ binê³¼ room_entry_sequence ë¶€ì—¬
    """
    if df.empty:
        return df
    
    print("ğŸ”¢ 1ì°¨ ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ binê³¼ room_entry_sequence ë¶€ì—¬ ì¤‘...")
    
    df = df.copy()
    
    # ë°©ë³„ë¡œ ì²˜ë¦¬
    for room_num in df['roomNumber'].unique():
        room_mask = df['roomNumber'] == room_num
        room_data = df[room_mask]
        room_indices = room_data.index
        total_requests = len(room_data)
        
        # room_entry_sequence í• ë‹¹ (1ë¶€í„° ì‹œì‘)
        df.loc[room_indices, 'room_entry_sequence'] = range(1, total_requests + 1)
        
        # bin í• ë‹¹ (10ê°œ êµ¬ê°„ìœ¼ë¡œ ê· ë“± ë¶„í• )
        if total_requests <= BINS_COUNT:
            # ìš”ì²­ì´ 10ê°œ ì´í•˜ë©´ ê°ê°ì„ í•˜ë‚˜ì˜ binìœ¼ë¡œ
            bins = range(1, total_requests + 1)
        else:
            # 10ê°œ êµ¬ê°„ìœ¼ë¡œ ê· ë“± ë¶„í• 
            bins = pd.cut(range(total_requests), bins=BINS_COUNT, labels=range(1, BINS_COUNT + 1)).astype(int)
        
        df.loc[room_indices, 'bin'] = bins
        
        print(f"  ë°© {room_num}: {total_requests}ê°œ ë ˆì½”ë“œì— room_entry_sequence(1~{total_requests})ì™€ bin({len(set(bins))}ê°œ êµ¬ê°„) í• ë‹¹")
    
    print("âœ… binê³¼ room_entry_sequence ë¶€ì—¬ ì™„ë£Œ")
    return df


def sort_final_dataframe_simplified(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš© ë‹¨ìˆœí™”ëœ ì •ë ¬ ë¡œì§
    1ì°¨: ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ waiting_start_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    1ì°¨ ì •ë ¬ ì§í›„: binê³¼ room_entry_sequence ë¶€ì—¬
    2ì°¨: SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
    """
    if df.empty:
        return df
    
    print("ğŸ“Š ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš© ë‹¨ìˆœí™”ëœ ì •ë ¬ ë¡œì§ ì‹œì‘...")
    
    # 1ì°¨ ì •ë ¬: ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ waiting_start_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    if 'waiting_start_nanoTime' in df.columns:
        # ë‚˜ë…¸ì´ˆ ê°’ì„ ìˆ«ìë¡œ ë³€í™˜
        df['waiting_start_nanoTime_num'] = pd.to_numeric(df['waiting_start_nanoTime'], errors='coerce')
        df['waiting_start_nanoTime_num'] = df['waiting_start_nanoTime_num'].fillna(float('inf'))
        
        # ë°© ë²ˆí˜¸ â†’ waiting_start_nanoTime ìˆœìœ¼ë¡œ 1ì°¨ ì •ë ¬
        df = df.sort_values(['roomNumber', 'waiting_start_nanoTime_num']).reset_index(drop=True)
        
        print(f"âœ… 1ì°¨ ì •ë ¬ ì™„ë£Œ: ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ waiting_start_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬")
    else:
        print("âš ï¸ waiting_start_nanoTime ì»¬ëŸ¼ì´ ì—†ì–´ì„œ 1ì°¨ ì •ë ¬ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        df = df.sort_values(['roomNumber']).reset_index(drop=True)
    
    # 1ì°¨ ì •ë ¬ ì§í›„: binê³¼ room_entry_sequence ë¶€ì—¬
    df = assign_bins_and_sequence_after_first_sort(df)
    
    # 2ì°¨ ì •ë ¬: SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
    if 'critical_enter_nanoTime' in df.columns and 'join_result' in df.columns:
        
        # ë°©ë³„ë¡œ ì²˜ë¦¬
        final_df_list = []
        
        for room_num in df['roomNumber'].unique():
            room_df = df[df['roomNumber'] == room_num].copy()
            
            print(f"  ë°© {room_num}: SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTimeìœ¼ë¡œ ì¬ì •ë ¬ ì¤‘...")
            
            # SUCCESS/FAIL_OVER_CAPACITYì™€ ê¸°íƒ€ ë¶„ë¦¬
            paired_mask = (room_df['join_result'] == RESULT_SUCCESS) | (room_df['join_result'] == RESULT_FAIL_CAPACITY)
            room_paired = room_df[paired_mask].copy()
            room_others = room_df[~paired_mask].copy()
            
            if not room_paired.empty:
                # critical_enter_nanoTimeì„ ìˆ«ìë¡œ ë³€í™˜
                room_paired['critical_enter_nanoTime_num'] = pd.to_numeric(room_paired['critical_enter_nanoTime'], errors='coerce')
                room_paired['critical_enter_nanoTime_num'] = room_paired['critical_enter_nanoTime_num'].fillna(float('inf'))
                
                # SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTimeìœ¼ë¡œ ì¬ì •ë ¬
                room_paired = room_paired.sort_values(['critical_enter_nanoTime_num']).reset_index(drop=True)
                room_paired = room_paired.drop(columns=['critical_enter_nanoTime_num'])
                
                print(f"    SUCCESS/FAIL_OVER_CAPACITY {len(room_paired)}ê°œ ìŠ¤ë ˆë“œë¥¼ critical_enter_nanoTimeìœ¼ë¡œ ì¬ì •ë ¬")
            
            # ê¸°íƒ€ëŠ” ì›ë˜ waiting_start_nanoTime ìˆœì„œ ìœ ì§€
            if not room_others.empty:
                print(f"    ê¸°íƒ€ {len(room_others)}ê°œëŠ” waiting_start_nanoTime ìˆœì„œ ìœ ì§€")
            
            # ì¬ì •ë ¬ëœ ë°ì´í„° ê²°í•©
            room_result_list = []
            paired_idx = 0
            others_idx = 0
            
            for _, original_row in room_df.iterrows():
                if original_row['join_result'] == RESULT_SUCCESS or original_row['join_result'] == RESULT_FAIL_CAPACITY:
                    # SUCCESS/FAIL_OVER_CAPACITYëŠ” critical_enter_nanoTime ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ
                    if paired_idx < len(room_paired):
                        room_result_list.append(room_paired.iloc[paired_idx])
                        paired_idx += 1
                else:
                    # ê¸°íƒ€ëŠ” ì›ë˜ waiting_start_nanoTime ìˆœì„œ ìœ ì§€
                    if others_idx < len(room_others):
                        room_result_list.append(room_others.iloc[others_idx])
                        others_idx += 1
            
            # í˜¹ì‹œ ë‚¨ì€ ë°ì´í„°ë“¤ ì¶”ê°€
            while paired_idx < len(room_paired):
                room_result_list.append(room_paired.iloc[paired_idx])
                paired_idx += 1
            while others_idx < len(room_others):
                room_result_list.append(room_others.iloc[others_idx])
                others_idx += 1
            
            if room_result_list:
                room_final = pd.DataFrame(room_result_list).reset_index(drop=True)
                final_df_list.append(room_final)
        
        if final_df_list:
            df = pd.concat(final_df_list, ignore_index=True)
            print(f"âœ… 2ì°¨ ì •ë ¬ ì™„ë£Œ: SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTime ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬")
        else:
            print("âš ï¸ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ì–´ì„œ 2ì°¨ ì •ë ¬ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        print("âš ï¸ critical_enter_nanoTime ë˜ëŠ” join_result ì»¬ëŸ¼ì´ ì—†ì–´ì„œ 2ì°¨ ì •ë ¬ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # ì •ë ¬ìš© ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    if 'waiting_start_nanoTime_num' in df.columns:
        df = df.drop(columns=['waiting_start_nanoTime_num'])
    
    return df.reset_index(drop=True)


def build_clean_performance_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    íŒŒì‹±ëœ ë¡œê·¸ ë°ì´í„°ë¥¼ ì„±ëŠ¥ ë¶„ì„ìš© ë°ì´í„°ë¡œ ë³€í™˜ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
    
    ì²˜ë¦¬ ê³¼ì •:
        1. íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ ë° nanoTime ê¸°ì¤€ ì •ë ¬
        2. ì‚¬ìš©ìë³„ ì´ë²¤íŠ¸ í˜ì–´ë§ ì²˜ë¦¬ (5ê°œ ì´ë²¤íŠ¸ë§Œ)
        3. waiting_start_nanoTime ê¸°ì¤€ 1ì°¨ ì •ë ¬
        4. 1ì°¨ ì •ë ¬ ì§í›„ binê³¼ room_entry_sequence ë¶€ì—¬
        5. critical_enter_nanoTime ê¸°ì¤€ 2ì°¨ ì •ë ¬ (SUCCESS/FAIL_OVER_CAPACITYë§Œ)
    """
    if df.empty:
        return pd.DataFrame()
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # ë‚˜ë…¸ì´ˆ ê°’ë“¤ì„ ìˆ«ìë¡œ ë³€í™˜ (ì •ë ¬ìš©)
    df['nanoTime_num'] = df['nanoTime'].astype(float)
    df['epochNano_num'] = df['epochNano'].astype(float)
    
    # ë°©ë³„ + nanoTime ê¸°ì¤€ ì •ë ¬ (ê¸°ë³¸ ì •ë ¬ì€ ìœ ì§€)
    df = df.sort_values(['roomNumber', 'nanoTime_num']).reset_index(drop=True)
    
    performance_results = []
    
    # ê° ë°©ë³„ë¡œ ì²˜ë¦¬
    for room_num in df['roomNumber'].unique():
        print(f"ğŸ  ë°© {room_num} ì²˜ë¦¬ ì¤‘...")
        
        # ë°©ë³„ 5ê°œ ì´ë²¤íŠ¸ë“¤ì„ ì‚¬ìš©ìë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬
        room_events = df[df['roomNumber'] == room_num].copy()
        if not room_events.empty:
            for user_id, user_data in room_events.groupby('userId'):
                profile = process_user_events(user_id, user_data)
                performance_results.append(profile)
    
    if not performance_results:
        return pd.DataFrame()
    
    # DataFrame ìƒì„± ë° ì •ë¦¬
    result_df = pd.DataFrame(performance_results)
    
    # ë‚˜ë…¸ì´ˆ ì»¬ëŸ¼ë“¤ì„ ë¬¸ìì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜
    nano_columns = [col for col in result_df.columns if 'nanoTime' in col or 'epochNano' in col]
    for col in nano_columns:
        if col in result_df.columns:
            result_df[col] = result_df[col].astype(str)
    
    # ìµœì¢… ì •ë ¬: 1ì°¨ ì •ë ¬ â†’ bin/sequence ë¶€ì—¬ â†’ 2ì°¨ ì •ë ¬
    result_df = sort_final_dataframe_simplified(result_df)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    base_columns = ['roomNumber', 'bin', 'user_id', 'room_entry_sequence', 'join_result']
    event_columns = []
    
    # ì´ë²¤íŠ¸ë³„ ì»¬ëŸ¼ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
    for prefix in ['waiting_start', 'critical_enter', 'critical_leave', 'increment_before', 'increment_after']:
        for suffix in ['_time', '_nanoTime', '_epochNano', '_event_type']:
            col_name = prefix + suffix
            if col_name in result_df.columns:
                event_columns.append(col_name)
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    all_columns = base_columns + event_columns
    existing_columns = [col for col in all_columns if col in result_df.columns]
    result_df = result_df[existing_columns]
    
    return result_df


def get_clean_event_desc_table() -> List[List[str]]:
    """
    Excel íŒŒì¼ì— ì¶”ê°€í•  ì»¬ëŸ¼ ì„¤ëª… í…Œì´ë¸” ìƒì„± (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
    """
    return [
        ["ì†ì„±ëª…", "ì¸¡ì • ëª©ì ", "ë„ì¶œ ë°©ë²•"],
        ["roomNumber", "ë°© ë²ˆí˜¸ ì‹ë³„", "ë¡œê·¸ í•„ë“œ: roomNumber"],
        ["bin", "ë°©ë³„ ë¶„ì„ êµ¬ê°„", "ê° ë°©ì˜ ìš”ì²­ì„ 10ê°œ êµ¬ê°„ìœ¼ë¡œ ê· ë“± ë¶„í• "],
        ["user_id", "ì‚¬ìš©ì ì‹ë³„", "ë¡œê·¸ í•„ë“œ: userId"],
        ["room_entry_sequence", "ë°©ë³„ ì²˜ë¦¬ ìˆœë²ˆ", "ë‹¨ìˆœ ìˆœì°¨ í• ë‹¹"],
        ["join_result", "ì…ì¥ ê²°ê³¼ êµ¬ë¶„", "SUCCESS/FAIL_OVER_CAPACITY/UNKNOWN"],
        ["waiting_start_*", "ëŒ€ê¸° ì‹œì‘ ì‹œì ", "WAITING_START ì´ë²¤íŠ¸ ì†ì„±ë“¤"],
        ["critical_enter_*", "ì„ê³„êµ¬ì—­ ì§„ì… ì‹œì ", "CRITICAL_ENTER ì´ë²¤íŠ¸ ì†ì„±ë“¤"],
        ["critical_leave_*", "ì„ê³„êµ¬ì—­ ì§„ì¶œ ì‹œì ", "CRITICAL_LEAVE ì´ë²¤íŠ¸ ì†ì„±ë“¤"],
        ["increment_before_*", "ì¦ê°€ ì‘ì—… ì‹œì‘ ì‹œì ", "INCREMENT_BEFORE ì´ë²¤íŠ¸ ì†ì„±ë“¤"],
        ["increment_after_*", "ì¦ê°€ ì‘ì—… ì™„ë£Œ ì‹œì ", "INCREMENT_AFTER ì´ë²¤íŠ¸ ì†ì„±ë“¤"],
        ["*_time", "ì´ë²¤íŠ¸ ë°œìƒ ì‹œê°„", "timestampIso (í‘œì‹œìš©)"],
        ["*_nanoTime", "ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ì‹œê°„", "1ì°¨: waiting_start_nanoTime, 2ì°¨: critical_enter_nanoTime ì •ë ¬"],
        ["*_epochNano", "Epoch ë‚˜ë…¸ì´ˆ ì‹œê°„", "Epoch ê¸°ì¤€ ë‚˜ë…¸ì´ˆ (ì°¸ì¡°ìš©)"],
        ["*_event_type", "ì´ë²¤íŠ¸ ìƒì„¸ íƒ€ì…", "SUCCESS/FAIL_OVER_CAPACITY ë“±"],
        ["ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°", "ë½ ì™¸ë¶€ ì‚¬ì „ í™•ì¸ ì—†ìŒ", "PRE_CHECK_FAIL_OVER_CAPACITY ì´ë²¤íŠ¸ ì—†ìŒ"]
    ]


def convert_nano_value(x: Any) -> str:
    """
    ë‚˜ë…¸ì´ˆ ê°’ì„ ë¬¸ìì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
    """
    if pd.isna(x) or x == '' or str(x).lower() == 'nan':
        return ''
    try:
        return str(int(float(x)))
    except (ValueError, TypeError):
        return str(x)


def save_to_csv(df: pd.DataFrame, filepath: str) -> None:
    """
    DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥ (ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ìœ ì§€)
    """
    # ë‚˜ë…¸ì´ˆ ì»¬ëŸ¼ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì§€ìˆ˜ í‘œê¸°ë²• ë°©ì§€
    df_copy = df.copy()
    nano_columns = [col for col in df.columns if 'nanoTime' in col or 'epochNano' in col]
    
    for col in nano_columns:
        if col in df_copy.columns:
            df_copy[col] = df_copy[col].apply(convert_nano_value)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = os.path.dirname(filepath)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # UTF-8 with BOMìœ¼ë¡œ ì €ì¥ (Excelì—ì„œ í•œê¸€ ê¹¨ì§ ë°©ì§€)
    df_copy.to_csv(filepath, index=False, encoding='utf-8-sig')
    print(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")


def is_datetime_with_tz(column):
    """
    datetime ì»¬ëŸ¼ì˜ timezone ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” í˜¸í™˜ì„± í•¨ìˆ˜
    """
    try:
        # ìµœì‹  pandas ë²„ì „ ì‹œë„
        return pd.api.types.is_datetime64tz_dtype(column)
    except AttributeError:
        try:
            # êµ¬ë²„ì „ pandas ì‹œë„
            return pd.api.types.is_datetime64_tz_dtype(column)
        except AttributeError:
            # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ì§ì ‘ í™•ì¸
            return hasattr(column.dtype, 'tz') and column.dtype.tz is not None


def save_with_side_table(df: pd.DataFrame, filepath: str, desc_table: List[List[str]]) -> str:
    """
    DataFrameì„ Excelë¡œ ì €ì¥í•˜ê³  ì„¤ëª… í…Œì´ë¸” ì¶”ê°€ (pandas í˜¸í™˜ì„± ê°œì„ )
    """
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = os.path.dirname(filepath)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # timezone ì œê±°í•œ ë³µì‚¬ë³¸ ìƒì„± (í˜¸í™˜ì„± ê°œì„ )
    df_excel = df.copy()
    for col in df_excel.columns:
        if is_datetime_with_tz(df_excel[col]):
            df_excel[col] = df_excel[col].dt.tz_localize(None)
    
    # Excel íŒŒì¼ ìƒì„±
    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
        df_excel.to_excel(writer, index=False)
        
        # ë‚˜ë…¸ì´ˆ ì»¬ëŸ¼ë“¤ì„ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì„¤ì •
        workbook = writer.book
        worksheet = writer.sheets['Sheet1']
        
        nano_columns = [col for col in df.columns if 'nanoTime' in col or 'epochNano' in col]
        for col_name in nano_columns:
            col_idx = df.columns.get_loc(col_name) + 1
            for row in range(2, len(df) + 2):
                cell = worksheet.cell(row=row, column=col_idx)
                cell.number_format = '@'  # í…ìŠ¤íŠ¸ í˜•ì‹
    
    # ì„¤ëª… í…Œì´ë¸” ì¶”ê°€
    wb = load_workbook(filepath)
    ws = wb.active
    
    start_col = len(df.columns) + 2
    
    for i, row in enumerate(desc_table):
        for j, val in enumerate(row):
            ws.cell(row=i + 1, column=start_col + j, value=val)
    
    wb.save(filepath)
    print(f"Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    return filepath


def analyze_clean_results(df: pd.DataFrame) -> None:
    """
    ì²˜ë¦¬ ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
    """
    if df.empty:
        print("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_operations = len(df)
    
    print(f"\n{'='*60}")
    print(f"ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° ë¶„ì„ ê²°ê³¼")
    print(f"{'='*60}")
    print(f"ì „ì²´ ì²˜ë¦¬ ì‘ì—… ìˆ˜: {total_operations}")
    
    # ì…ì¥ ê²°ê³¼ë³„ ë¶„ì„
    if 'join_result' in df.columns:
        print(f"\n[ì…ì¥ ê²°ê³¼ë³„ ë¶„ì„]")
        join_result_counts = df['join_result'].value_counts()
        for result, count in join_result_counts.items():
            print(f"  {result}: {count}ê±´ ({count/total_operations*100:.1f}%)")
    
    # ì´ë²¤íŠ¸ ì™„ì„±ë„ ë¶„ì„
    events = ['waiting_start_time', 'critical_enter_time', 'critical_leave_time', 
              'increment_before_time', 'increment_after_time']
    
    print(f"\n[ì´ë²¤íŠ¸ ì™„ì„±ë„ ë¶„ì„]")
    for event in events:
        if event in df.columns:
            complete_count = df[event].notna().sum()
            print(f"  {event}: {complete_count}ê±´ ({complete_count/total_operations*100:.1f}%)")
    
    # ì™„ì „í•œ 5ê°œ ì´ë²¤íŠ¸ ì„¸ì…˜ ë¶„ì„
    complete_sessions = 0
    success_complete = 0
    fail_complete = 0
    
    for _, row in df.iterrows():
        if all(pd.notna(row.get(event)) and row.get(event) != '' for event in events):
            complete_sessions += 1
            if row.get('join_result') == RESULT_SUCCESS:
                success_complete += 1
            elif row.get('join_result') == RESULT_FAIL_CAPACITY:
                fail_complete += 1
    
    print(f"\n[ì™„ì „í•œ 5ê°œ ì´ë²¤íŠ¸ ì„¸ì…˜ ë¶„ì„]")
    print(f"  ì™„ì „í•œ ì„¸ì…˜: {complete_sessions}ê±´ ({complete_sessions/total_operations*100:.1f}%)")
    print(f"    - ì„±ê³µ: {success_complete}ê±´")
    print(f"    - ì‹¤íŒ¨: {fail_complete}ê±´")
    
    # ë°©ë³„ ì„±ëŠ¥ í†µê³„
    print(f"\n[ë°©ë³„ ì„±ëŠ¥ í†µê³„]")
    room_stats = df.groupby('roomNumber').agg({
        'user_id': 'count',
        'bin': 'nunique'
    })
    room_stats.columns = ['total_operations', 'bin_count']
    
    for room_num, stats in room_stats.iterrows():
        print(f"  ë°© {room_num}: ì´ {stats['total_operations']}íšŒ, êµ¬ê°„ ìˆ˜: {stats['bin_count']}")
        
        if 'join_result' in df.columns:
            room_data = df[df['roomNumber'] == room_num]
            room_results = room_data['join_result'].value_counts()
            for result, count in room_results.items():
                print(f"    - {result}: {count}ê±´")
    
    # ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° íŠ¹ì§• í™•ì¸
    print(f"\n[ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° íŠ¹ì§• í™•ì¸]")
    print(f"  - PRE_CHECK_FAIL ì´ë²¤íŠ¸: 0ê±´ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ì—ì„œëŠ” ë°œìƒí•˜ì§€ ì•ŠìŒ)")
    print(f"  - ë½ ì™¸ë¶€ ì‚¬ì „ í™•ì¸ ì—†ìŒ")
    print(f"  - 5ê°œ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬ (SUCCESS/FAIL_OVER_CAPACITY/UNKNOWN)")
    
    # ë‹¨ìˆœí™”ëœ ì •ë ¬ ìˆœì„œ í™•ì¸
    print(f"\n[ë‹¨ìˆœí™”ëœ ì •ë ¬ ìˆœì„œ í™•ì¸]")
    if 'waiting_start_nanoTime' in df.columns and 'critical_enter_nanoTime' in df.columns:
        for room_num in sorted(df['roomNumber'].unique())[:3]:  # ì²« 3ê°œ ë°©ë§Œ í™•ì¸
            room_data = df[df['roomNumber'] == room_num].head(5)
            print(f"  ë°© {room_num}:")
            for i, (_, row) in enumerate(room_data.iterrows()):
                seq = row['room_entry_sequence']
                waiting_nano = row.get('waiting_start_nanoTime', 'N/A')
                critical_nano = row.get('critical_enter_nanoTime', 'N/A')
                user_id = row['user_id']
                result = row['join_result']
                print(f"    ìˆœë²ˆ{seq}: waiting={waiting_nano}, critical={critical_nano} (user: {user_id}, result:{result})")
    else:
        print("  í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë‚˜ë…¸ì´ˆ ì •ë°€ë„ í™•ì¸
    print(f"\n[ë‚˜ë…¸ì´ˆ ì •ë°€ë„ í™•ì¸ (ì²« 3ê°œ ìƒ˜í”Œ)]")
    nano_columns = [col for col in df.columns if 'nanoTime' in col]
    if nano_columns:
        for i in range(min(3, len(df))):
            print(f"  ìƒ˜í”Œ {i+1}:")
            for col in nano_columns[:3]:  # ì²« 3ê°œ ë‚˜ë…¸ì´ˆ ì»¬ëŸ¼ë§Œ
                if col in df.columns:
                    print(f"    {col}: {df.iloc[i][col]}")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
    """
    parser = argparse.ArgumentParser(
        description="ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš© ì „ì²˜ë¦¬ê¸°: PRE_CHECK_FAIL ì—†ëŠ” 5ê°œ ì´ë²¤íŠ¸ ì²˜ë¦¬",
        epilog="ì˜ˆì‹œ: py -3 preprocess_logs_single_check.py --output_dir C:\\single_check_analysis\\ --room 1 --xlsx single_check_output.xlsx"
    )
    parser.add_argument('--output_dir', type=str, default='results_single_check', 
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: results_single_check)')
    parser.add_argument('--room', type=int, help='íŠ¹ì • ë°© ë²ˆí˜¸ë§Œ ì²˜ë¦¬ (ì˜µì…˜)')
    parser.add_argument('--csv', type=str, help='ì¶”ê°€ CSV íŒŒì¼ëª… (ì˜µì…˜)')
    parser.add_argument('--xlsx', type=str, help='Excel íŒŒì¼ëª… (ì˜µì…˜)')
    parser.add_argument('--test', action='store_true', help='ì •ê·œì‹ íŒ¨í„´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    # ì •ê·œì‹ í…ŒìŠ¤íŠ¸ ì˜µì…˜
    if args.test:
        print("ğŸ§ª CRITICAL_PATTERN ì •ê·œì‹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹„ì´ì¤‘ í™•ì¸ìš©)...")
        test_result = test_critical_pattern()
        if test_result:
            print("âœ… ì •ê·œì‹ í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print("âŒ ì •ê·œì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - íŒ¨í„´ì„ ì¬ê²€í† í•˜ì„¸ìš”")
        return
    
    try:
        # 1. ë¡œê·¸ íŒŒì¼ êµì²´
        replace_log_file()
        
        # 2. ë¡œê·¸ íŒŒì‹±
        print(f"\në¡œê·¸ íŒŒì¼ íŒŒì‹± ì¤‘ (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°)...")
        df = parse_five_events_clean(LOG_FILE, room_number=args.room)
        print(f"íŒŒì‹± ì™„ë£Œ: {len(df)}ê°œ ì´ë²¤íŠ¸")
        
        # 3. ì„±ëŠ¥ ë°ì´í„° êµ¬ì¶• (ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡°ìš©)
        print(f"\në¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° ë°ì´í„° êµ¬ì¶• ì¤‘...")
        result = build_clean_performance_data(df)
        print(f"êµ¬ì¶• ì™„ë£Œ: {len(result)}ê°œ ì„¸ì…˜")
        
        # 4. ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • ë° ìƒì„±
        output_dir = args.output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
        
        # 5. ê¸°ë³¸ CSV íŒŒì¼ ì €ì¥
        if args.room:
            base_filename = f'room{args.room}_single_check.csv'
        else:
            base_filename = 'all_rooms_single_check.csv'
        
        csv_path = os.path.join(output_dir, base_filename)
        save_to_csv(result, csv_path)
        
        # 6. ì¶”ê°€ CSV íŒŒì¼ ì €ì¥ (ì˜µì…˜)
        if args.csv:
            additional_csv_path = os.path.join(output_dir, args.csv)
            save_to_csv(result, additional_csv_path)
        
        # 7. Excel íŒŒì¼ ì €ì¥ (ì˜µì…˜)
        if args.xlsx:
            xlsx_path = os.path.join(output_dir, args.xlsx)
            desc_table = get_clean_event_desc_table()
            save_with_side_table(result, xlsx_path, desc_table)
        
        # 8. ê²°ê³¼ ë¶„ì„ ì¶œë ¥
        analyze_clean_results(result)
        
        print(f"\n{'='*60}")
        print(f"ë¹„ì´ì¤‘ í™•ì¸ êµ¬ì¡° ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"íŠ¹ì§•: PRE_CHECK_FAIL ì´ë²¤íŠ¸ ì—†ìŒ, 5ê°œ ì´ë²¤íŠ¸ë§Œ ì²˜ë¦¬")
        print(f"ì •ë ¬ ìˆœì„œ: 1ì°¨(waiting_start_nanoTime) â†’ 2ì°¨(SUCCESS/FAIL_OVER_CAPACITYë§Œ critical_enter_nanoTime)")
        print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {os.path.abspath(output_dir)}")
        print(f"{'='*60}")
        
    except FileNotFoundError as e:
        print(f"\nì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {e}")
        sys.exit(1)
    except PermissionError as e:
        print(f"\nì˜¤ë¥˜: íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤ - {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í˜¸ì¶œ
if __name__ == '__main__':
    main()
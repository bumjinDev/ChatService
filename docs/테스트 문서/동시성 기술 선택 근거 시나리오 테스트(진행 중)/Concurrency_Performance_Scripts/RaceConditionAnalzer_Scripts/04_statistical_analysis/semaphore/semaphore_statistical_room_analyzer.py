#!/usr/bin/env python3
"""
Semaphore ë°©ë³„ í†µê³„ ë¶„ì„ê¸°
- ì„¸ë§ˆí¬ì–´ì˜ 3ê°€ì§€ í•µì‹¬ ë¶„ì„ ì˜ì—­ì„ ë°©ë³„ë¡œ í†µê³„ ì§‘ê³„
- ë¶„ì„ 1: ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ê´€ì°° (ê·œì¹™ 1+4 í†µí•©) - í˜„ìƒ ê´€ì°°
- ë¶„ì„ 2: ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ê´€ì°° (ê·œì¹™ 2 ì¬ì •ì˜) - í˜„ìƒ ê´€ì°°  
- ë¶„ì„ 3: ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦ (ê·œì¹™ 3 ìœ ì§€) - ì„±ê³µ/ì‹¤íŒ¨ íŒì •
"""

import pandas as pd
import numpy as np
from datetime import datetime
import argparse
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.utils import get_column_letter
from openpyxl.styles import Font, PatternFill, Alignment
import traceback

def load_and_validate_semaphore_data(preprocessor_file, analysis_file):
    """ì„¸ë§ˆí¬ì–´ ë°ì´í„° ë¡œë“œ ë° í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦"""
    print("ğŸ“‚ ì„¸ë§ˆí¬ì–´ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘...")
    
    # ì „ì²˜ë¦¬ ë°ì´í„° ë¡œë“œ
    preprocessor_df = pd.read_csv(preprocessor_file)
    print(f"âœ… ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(preprocessor_df)}í–‰")
    
    # ë¶„ì„ ê²°ê³¼ ë°ì´í„° ë¡œë“œ
    analysis_df = pd.read_csv(analysis_file)
    print(f"âœ… ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(analysis_df)}í–‰")
    
    # ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ (10ê°œ ì»¬ëŸ¼)
    preprocessor_required = ['roomNumber', 'bin', 'user_id', 'prev_people', 'curr_people', 
                           'max_people', 'room_entry_sequence', 'join_result',
                           'true_critical_section_nanoTime_start', 'true_critical_section_nanoTime_end']
    missing_preprocessor = [col for col in preprocessor_required if col not in preprocessor_df.columns]
    if missing_preprocessor:
        raise ValueError(f"ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ ë°ì´í„°ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_preprocessor}")
    
    # ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ (14ê°œ ì»¬ëŸ¼)
    analysis_required = ['roomNumber', 'bin', 'user_id', 'anomaly_type', 
                        'over_capacity_amount', 'over_capacity_curr', 'over_capacity_max']
    missing_analysis = [col for col in analysis_required if col not in analysis_df.columns]
    if missing_analysis:
        raise ValueError(f"ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ ë°ì´í„°ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_analysis}")
    
    # ë°ì´í„° íƒ€ì… ì •ë¦¬
    preprocessor_df['roomNumber'] = pd.to_numeric(preprocessor_df['roomNumber'], errors='coerce').fillna(0).astype(int)
    preprocessor_df['bin'] = pd.to_numeric(preprocessor_df['bin'], errors='coerce').fillna(0).astype(int)
    
    analysis_df['roomNumber'] = pd.to_numeric(analysis_df['roomNumber'], errors='coerce').fillna(0).astype(int)
    analysis_df['bin'] = pd.to_numeric(analysis_df['bin'], errors='coerce').fillna(0).astype(int)
    
    print("âœ… ì„¸ë§ˆí¬ì–´ ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ë³€í™˜ ì™„ë£Œ")
    return preprocessor_df, analysis_df

def calculate_total_requests_per_room(preprocessor_df):
    """ë°©ë³„ ì „ì²´ ìš”ì²­ìˆ˜ ì§‘ê³„ (ëª¨ë“  bin í†µí•©)"""
    print("ğŸ“Š ë°©ë³„ ì „ì²´ ìš”ì²­ìˆ˜ ì§‘ê³„ ì¤‘...")
    
    total_requests = preprocessor_df.groupby(['roomNumber']).size().reset_index(name='total_requests')
    
    print(f"âœ… ì§‘ê³„ ì™„ë£Œ: {len(total_requests)}ê°œ ë°©")
    return total_requests

def analyze_sequential_consistency_per_room(preprocessor_df, analysis_df, total_requests_df):
    """ë¶„ì„ 1: ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ê´€ì°° (ê·œì¹™ 1+4 í†µí•©) - í˜„ìƒ ê´€ì°°"""
    print("ğŸ” ë¶„ì„ 1: ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ê´€ì°° (ê·œì¹™ 1+4 í†µí•©) ì¤‘...")
    
    # ì „ì²´ ë°© ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ìƒì„±
    result_stats = total_requests_df.copy()
    
    # í†µê³„ ì»¬ëŸ¼ë“¤ ì´ˆê¸°í™”
    result_stats['ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ê±´ìˆ˜'] = 0
    result_stats['ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ë°œìƒë¥  (%)'] = 0.0
    result_stats['ìˆœì°¨ì  ì²˜ë¦¬ ì¼ì¹˜ìœ¨ (%)'] = 100.0
    result_stats['í‰ê·  ì°¨ì´ í¬ê¸°'] = 0.0
    result_stats['ìµœì†Œ ì°¨ì´'] = np.nan
    result_stats['ìµœëŒ€ ì°¨ì´'] = np.nan
    result_stats['ì¤‘ê°„ê°’ ì°¨ì´'] = np.nan
    result_stats['ì°¨ì´ í‘œì¤€í¸ì°¨'] = 0.0
    
    # ë°©ë³„ë¡œ ìˆœì°¨ì  ì¼ê´€ì„± ë¶„ì„
    for room_num in preprocessor_df['roomNumber'].unique():
        room_data = preprocessor_df[preprocessor_df['roomNumber'] == room_num].copy()
        
        if len(room_data) == 0:
            continue
            
        # room_entry_sequence ê¸°ë°˜ ì´ìƒì  ìˆœì°¨ ìƒíƒœ ê³„ì‚°
        differences = []
        for _, row in room_data.iterrows():
            initial_people = 1  # í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œ ë°©ì— 1ëª… ì¡´ì¬
            ideal_sequential_state = min(initial_people + row['room_entry_sequence'], row['max_people'])
            
            if row['curr_people'] != ideal_sequential_state:
                diff = abs(row['curr_people'] - ideal_sequential_state)
                differences.append(diff)
        
        # ê²°ê³¼ DataFrameì—ì„œ í•´ë‹¹ ë°© ì°¾ê¸°
        mask = (result_stats['roomNumber'] == room_num)
        row_idx = result_stats[mask].index
        
        if len(row_idx) == 0:
            continue
            
        row_idx = row_idx[0]
        total_requests = result_stats.loc[row_idx, 'total_requests']
        
        # í†µê³„ ê³„ì‚°
        difference_count = len(differences)
        difference_rate = (difference_count / total_requests * 100) if total_requests > 0 else 0
        consistency_rate = ((total_requests - difference_count) / total_requests * 100) if total_requests > 0 else 100
        
        # ê²°ê³¼ ì—…ë°ì´íŠ¸
        result_stats.loc[row_idx, 'ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ê±´ìˆ˜'] = difference_count
        result_stats.loc[row_idx, 'ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ë°œìƒë¥  (%)'] = round(difference_rate, 2)
        result_stats.loc[row_idx, 'ìˆœì°¨ì  ì²˜ë¦¬ ì¼ì¹˜ìœ¨ (%)'] = round(consistency_rate, 2)
        
        if len(differences) > 0:
            differences_array = np.array(differences)
            result_stats.loc[row_idx, 'í‰ê·  ì°¨ì´ í¬ê¸°'] = round(differences_array.mean(), 2)
            result_stats.loc[row_idx, 'ìµœì†Œ ì°¨ì´'] = round(differences_array.min(), 2)
            result_stats.loc[row_idx, 'ìµœëŒ€ ì°¨ì´'] = round(differences_array.max(), 2)
            result_stats.loc[row_idx, 'ì¤‘ê°„ê°’ ì°¨ì´'] = round(np.median(differences_array), 2)
            result_stats.loc[row_idx, 'ì°¨ì´ í‘œì¤€í¸ì°¨'] = round(differences_array.std(), 4) if len(differences) > 1 else 0.0
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    final_columns = {
        'roomNumber': 'ë°© ë²ˆí˜¸',
        'total_requests': 'ì „ì²´ ìš”ì²­ìˆ˜'
    }
    
    result_stats = result_stats.rename(columns=final_columns)
    
    print(f"âœ… ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ë¶„ì„ ì™„ë£Œ: {len(result_stats)}ê°œ ë°©")
    return result_stats

def calculate_statistics(filtered_df, value_column, total_requests_df, use_absolute=False):
    """ë°©ë³„ í†µê³„ ê³„ì‚° í•¨ìˆ˜ - ê¸°ì¡´ ë™ì‹œì„± ì¸¡ì •ê³¼ ë™ì¼í•œ ë°©ì‹"""
    # ì „ì²´ ë°© ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ìƒì„±
    result_stats = total_requests_df.copy()
    
    # í†µê³„ ì»¬ëŸ¼ë“¤ ì´ˆê¸°í™” (ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼)
    result_stats['occurrence_count'] = 0
    result_stats['occurrence_rate'] = 0.0
    result_stats['sum_value'] = 0.0
    result_stats['avg_value'] = np.nan
    result_stats['min_value'] = np.nan
    result_stats['max_value'] = np.nan
    result_stats['median_value'] = np.nan
    result_stats['std_value'] = 0.0
    
    # ì´ìƒí˜„ìƒì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹¤ì œ í†µê³„ ê³„ì‚°
    if len(filtered_df) > 0:
        # roomNumber ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
        grouped = filtered_df.groupby(['roomNumber'])
        
        for room_num, group in grouped:
            # í•´ë‹¹ ë°©ì˜ ëª¨ë“  ê°’ë“¤ ì¶”ì¶œ (NaN ì œê±°)
            values = group[value_column].dropna()
            
            if len(values) == 0:
                continue
            
            # ê²°ê³¼ DataFrameì—ì„œ í•´ë‹¹ ë°© ì°¾ê¸°
            mask = (result_stats['roomNumber'] == room_num)
            row_idx = result_stats[mask].index
            
            if len(row_idx) == 0:
                continue
                
            row_idx = row_idx[0]
            total_requests = result_stats.loc[row_idx, 'total_requests']
            
            # í†µê³„ ê³„ì‚°
            occurrence_count = len(values)
            occurrence_rate = (occurrence_count / total_requests * 100) if total_requests > 0 else 0
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸ (ì ˆëŒ“ê°’ ì˜µì…˜ ì ìš©)
            result_stats.loc[row_idx, 'occurrence_count'] = int(occurrence_count)
            result_stats.loc[row_idx, 'occurrence_rate'] = round(occurrence_rate, 2)
            
            if use_absolute:
                result_stats.loc[row_idx, 'sum_value'] = round(values.abs().sum(), 2)
                result_stats.loc[row_idx, 'avg_value'] = round(values.abs().mean(), 2)
            else:
                result_stats.loc[row_idx, 'sum_value'] = round(values.sum(), 2)
                result_stats.loc[row_idx, 'avg_value'] = round(values.mean(), 2)
            
            result_stats.loc[row_idx, 'min_value'] = round(values.min(), 2)
            result_stats.loc[row_idx, 'max_value'] = round(values.max(), 2)
            result_stats.loc[row_idx, 'median_value'] = round(values.median(), 2)
            result_stats.loc[row_idx, 'std_value'] = round(values.std(), 4) if len(values) > 1 else 0.0
    
    # ë°ì´í„° íƒ€ì… ì •ë¦¬
    result_stats['roomNumber'] = result_stats['roomNumber'].astype(int)
    result_stats['total_requests'] = result_stats['total_requests'].astype(int)
    result_stats['occurrence_count'] = result_stats['occurrence_count'].fillna(0).astype(int)
    
    return result_stats

def analyze_concurrent_execution_per_room(preprocessor_df, analysis_df, total_requests_df):
    """ë¶„ì„ 2: ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ê´€ì°° (ê·œì¹™ 2 ì¬ì •ì˜) - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í†µì¼"""
    print("ğŸ” ë¶„ì„ 2: ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ê´€ì°° (ê·œì¹™ 2 ì¬ì •ì˜) ì¤‘...")
    
    # contention_group_size ë°ì´í„°ê°€ ìˆëŠ” ë ˆì½”ë“œ í•„í„°ë§ (ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼)
    filtered_df = analysis_df[
        (analysis_df['contention_group_size'].notna()) & 
        (analysis_df['contention_group_size'] > 1)
    ]
    print(f"  - ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê´€ë ¨ ë ˆì½”ë“œ: {len(filtered_df)}ê±´")
    
    # contention_group_size ê¸°ì¤€ í†µê³„ ê³„ì‚° (ê¸°ì¡´ calculate_statistics ë°©ì‹ ì‚¬ìš©)
    stats_df = calculate_statistics(filtered_df, 'contention_group_size', total_requests_df)
    
    # ì»¬ëŸ¼ëª… ë³€ê²½ (ê¸°ì¡´ ë™ì‹œì„± ì¸¡ì •ê³¼ ë™ì¼í•˜ê²Œ)
    column_mapping = {
        'sum_value': 'ì´ ê²½í•© ìŠ¤ë ˆë“œ ìˆ˜',
        'avg_value': 'í‰ê·  ê²½í•© ìŠ¤ë ˆë“œ ìˆ˜',
        'min_value': 'ìµœì†Œ ê²½í•© ê·¸ë£¹ í¬ê¸°',
        'max_value': 'ìµœëŒ€ ê²½í•© ìŠ¤ë ˆë“œ ìˆ˜',
        'median_value': 'ì¤‘ê°„ê°’ ê²½í•© ê·¸ë£¹ í¬ê¸°',
        'std_value': 'ê²½í•© ê°•ë„ í‘œì¤€í¸ì°¨'
    }
    
    final_columns = {
        'roomNumber': 'ë°© ë²ˆí˜¸',
        'total_requests': 'ì „ì²´ ìš”ì²­ìˆ˜',
        'occurrence_count': 'ë°œìƒ ê±´ìˆ˜',
        'occurrence_rate': 'ë°œìƒë¥  (%)',
        **column_mapping
    }
    
    stats_df = stats_df.rename(columns=final_columns)
    
    print(f"âœ… ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ë¶„ì„ ì™„ë£Œ: {len(stats_df)}ê°œ ë°©")
    return stats_df

def analyze_capacity_prevention_per_room(preprocessor_df, analysis_df, total_requests_df):
    """ë¶„ì„ 3: ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦ (ê·œì¹™ 3 ìœ ì§€) - ì„±ê³µ/ì‹¤íŒ¨ íŒì •"""
    print("ğŸ” ë¶„ì„ 3: ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦ (ê·œì¹™ 3 ìœ ì§€) ì¤‘...")
    
    # anomaly_typeì´ NaNì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    analysis_df['anomaly_type'] = analysis_df['anomaly_type'].fillna('')
    
    # ì „ì²´ ë°© ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ìƒì„±
    result_stats = total_requests_df.copy()
    
    # í†µê³„ ì»¬ëŸ¼ë“¤ ì´ˆê¸°í™”
    result_stats['ì •ì› ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜'] = 0
    result_stats['ì •ì› ì´ˆê³¼ ë°œìƒë¥  (%)'] = 0.0
    result_stats['ì •ì› ì´ˆê³¼ ë°©ì§€ ì„±ê³µë¥  (%)'] = 100.0
    result_stats['í‰ê·  ì´ˆê³¼ ì¸ì›'] = 0.0
    result_stats['ìµœì†Œ ì´ˆê³¼ ì¸ì›'] = np.nan
    result_stats['ìµœëŒ€ ì´ˆê³¼ ì¸ì›'] = np.nan
    result_stats['ì¤‘ê°„ê°’ ì´ˆê³¼ ì¸ì›'] = np.nan
    result_stats['ì´ˆê³¼ ê·œëª¨ í‘œì¤€í¸ì°¨'] = 0.0
    
    # ì •ì› ì´ˆê³¼ ì˜¤ë¥˜ í•„í„°ë§
    capacity_exceeded = analysis_df[analysis_df['anomaly_type'].str.contains('ì •ì› ì´ˆê³¼ ì˜¤ë¥˜', na=False)]
    
    if len(capacity_exceeded) > 0:
        # ë°©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í†µê³„ ê³„ì‚°
        grouped = capacity_exceeded.groupby(['roomNumber'])
        
        for room_num, group in grouped:
            # í•´ë‹¹ ë°©ì˜ ëª¨ë“  ì´ˆê³¼ ì¸ì› ê°’ë“¤ ì¶”ì¶œ
            exceeded_amounts = group['over_capacity_amount'].dropna()
            
            if len(exceeded_amounts) == 0:
                continue
            
            # ê²°ê³¼ DataFrameì—ì„œ í•´ë‹¹ ë°© ì°¾ê¸°
            mask = (result_stats['roomNumber'] == room_num)
            row_idx = result_stats[mask].index
            
            if len(row_idx) == 0:
                continue
                
            row_idx = row_idx[0]
            total_requests = result_stats.loc[row_idx, 'total_requests']
            
            # í†µê³„ ê³„ì‚°
            exceeded_count = len(exceeded_amounts)
            exceeded_rate = (exceeded_count / total_requests * 100) if total_requests > 0 else 0
            prevention_rate = ((total_requests - exceeded_count) / total_requests * 100) if total_requests > 0 else 100
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            result_stats.loc[row_idx, 'ì •ì› ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜'] = exceeded_count
            result_stats.loc[row_idx, 'ì •ì› ì´ˆê³¼ ë°œìƒë¥  (%)'] = round(exceeded_rate, 2)
            result_stats.loc[row_idx, 'ì •ì› ì´ˆê³¼ ë°©ì§€ ì„±ê³µë¥  (%)'] = round(prevention_rate, 2)
            result_stats.loc[row_idx, 'í‰ê·  ì´ˆê³¼ ì¸ì›'] = round(exceeded_amounts.mean(), 2)
            result_stats.loc[row_idx, 'ìµœì†Œ ì´ˆê³¼ ì¸ì›'] = round(exceeded_amounts.min(), 2)
            result_stats.loc[row_idx, 'ìµœëŒ€ ì´ˆê³¼ ì¸ì›'] = round(exceeded_amounts.max(), 2)
            result_stats.loc[row_idx, 'ì¤‘ê°„ê°’ ì´ˆê³¼ ì¸ì›'] = round(exceeded_amounts.median(), 2)
            result_stats.loc[row_idx, 'ì´ˆê³¼ ê·œëª¨ í‘œì¤€í¸ì°¨'] = round(exceeded_amounts.std(), 4) if len(exceeded_amounts) > 1 else 0.0
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    final_columns = {
        'roomNumber': 'ë°© ë²ˆí˜¸',
        'total_requests': 'ì „ì²´ ìš”ì²­ìˆ˜'
    }
    
    result_stats = result_stats.rename(columns=final_columns)
    
    print(f"âœ… ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦ ì™„ë£Œ: {len(result_stats)}ê°œ ë°©")
    return result_stats

def add_dataframe_to_sheet(ws, df, sheet_title):
    """DataFrameì„ ì›Œí¬ì‹œíŠ¸ì— ì¶”ê°€ (ë‹¨ìˆœí™”ëœ ìŠ¤íƒ€ì¼)"""
    # ì‹œíŠ¸ ì œëª© ì¶”ê°€
    ws['A1'] = sheet_title
    ws['A1'].font = Font(size=14, bold=True)
    
    # ì‹œì‘ í–‰
    start_row = 3
    
    # ì»¬ëŸ¼ í—¤ë” ì¶”ê°€
    for col_idx, column in enumerate(df.columns, 1):
        # ì»¬ëŸ¼ëª… ê¸¸ì´ ì œí•œ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        safe_column = str(column).replace('%', 'percent').replace('(', '').replace(')', '')[:30]
        cell = ws.cell(row=start_row, column=col_idx, value=safe_column)
        cell.font = Font(bold=True)
    
    # ë°ì´í„° ì¶”ê°€
    for row_idx, row in enumerate(df.itertuples(index=False), start_row + 1):
        for col_idx, value in enumerate(row, 1):
            # ë°ì´í„° ê°’ ì•ˆì „ì„± ì²˜ë¦¬
            safe_value = value
            if isinstance(value, str):
                safe_value = str(value).replace('%', 'percent')[:100]
            elif pd.isna(value):
                safe_value = ""
            
            cell = ws.cell(row=row_idx, column=col_idx, value=safe_value)
    
    # ì»¬ëŸ¼ ë„ˆë¹„ ê¸°ë³¸ ì„¤ì •
    for col_idx in range(1, len(df.columns) + 1):
        ws.column_dimensions[get_column_letter(col_idx)].width = 15

def create_excel_output(sequential_df, concurrent_df, capacity_df, output_file):
    """3ê°œ ì‹œíŠ¸ë¡œ êµ¬ì„±ëœ Excel íŒŒì¼ ìƒì„± (ì•ˆì „í•œ ë°©ì‹)"""
    print("ğŸ“Š ì„¸ë§ˆí¬ì–´ ë°©ë³„ Excel íŒŒì¼ ìƒì„± ì¤‘...")
    
    wb = Workbook()
    
    # ê¸°ë³¸ ì‹œíŠ¸ ì œê±°
    wb.remove(wb.active)
    
    # ì‹œíŠ¸ 1: ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ë¶„ì„
    ws1 = wb.create_sheet("Room_Sequential_Analysis")
    add_dataframe_to_sheet(ws1, sequential_df, "Room Analysis 1: Sequential Consistency")
    
    # ì‹œíŠ¸ 2: ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ë¶„ì„ (ì‹œíŠ¸ëª… ë³€ê²½: ê¸°ì¡´ê³¼ í†µì¼)
    ws2 = wb.create_sheet("Room_Contention_Analysis")
    add_dataframe_to_sheet(ws2, concurrent_df, "Room Analysis 2: Contention")
    
    # ì‹œíŠ¸ 3: ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦
    ws3 = wb.create_sheet("Room_Capacity_Analysis")
    add_dataframe_to_sheet(ws3, capacity_df, "Room Analysis 3: Capacity Prevention")
    
    wb.save(output_file)
    print(f"âœ… ì„¸ë§ˆí¬ì–´ ë°©ë³„ Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    print("  ğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸:")
    print("    - Room_Sequential_Analysis: ìˆœì°¨ì  ì¼ê´€ì„± ë°©ë³„ ê´€ì°°")
    print("    - Room_Contention_Analysis: ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ë°©ë³„ ê´€ì°° (ê¸°ì¡´ê³¼ í†µì¼)")
    print("    - Room_Capacity_Analysis: ì •ì› ì´ˆê³¼ ë°©ì§€ ë°©ë³„ ê²€ì¦")

def print_summary_statistics(sequential_df, concurrent_df, capacity_df, total_requests_df):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ í†µê³„ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“ˆ SEMAPHORE ë°©ë³„ í†µê³„ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    total_rooms = len(total_requests_df)
    total_requests_sum = total_requests_df['total_requests'].sum()
    
    print(f"ì „ì²´ ë¶„ì„ ëŒ€ìƒ: {total_rooms}ê°œ ë°©")
    print(f"ì „ì²´ ìš”ì²­ ìˆ˜: {total_requests_sum:,}ê±´")
    
    print(f"\n--- ì„¸ë§ˆí¬ì–´ 3ê°€ì§€ ë¶„ì„ ê²°ê³¼ ---")
    
    # ë¶„ì„ 1: ìˆœì°¨ì  ì¼ê´€ì„±
    if len(sequential_df) > 0:
        sequential_differences = sequential_df['ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ê±´ìˆ˜'].sum()
        print(f"ë¶„ì„ 1 (ìˆœì°¨ì  ì¼ê´€ì„± ê´€ì°°): {total_rooms}ê°œ ë°©ì—ì„œ {sequential_differences}ê±´ ì°¨ì´ ê´€ì°°")
    
    # ë¶„ì„ 2: ë™ì‹œ ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¶œë ¥)
    if len(concurrent_df) > 0:
        concurrent_executions = concurrent_df['ë°œìƒ ê±´ìˆ˜'].sum()
        max_concurrent_level = concurrent_df['ìµœëŒ€ ê²½í•© ìŠ¤ë ˆë“œ ìˆ˜'].max()
        print(f"ë¶„ì„ 2 (ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê´€ì°°): {total_rooms}ê°œ ë°©ì—ì„œ {concurrent_executions}ê±´ ê²½í•© ê´€ì°° (ìµœëŒ€ {max_concurrent_level}ê°œ ìŠ¤ë ˆë“œ)")
    
    # ë¶„ì„ 3: ì •ì› ì´ˆê³¼
    if len(capacity_df) > 0:
        capacity_exceeded = capacity_df['ì •ì› ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜'].sum()
        affected_rooms = len(capacity_df[capacity_df['ì •ì› ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜'] > 0])
        print(f"ë¶„ì„ 3 (ì •ì› ì´ˆê³¼ ë°©ì§€ ê²€ì¦): {affected_rooms}ê°œ ë°©ì—ì„œ {capacity_exceeded}ê±´ ì´ˆê³¼ ë°œìƒ")
    
    print(f"\n--- ì„¸ë§ˆí¬ì–´ ì¢…í•© í‰ê°€ ---")
    if len(capacity_df) > 0 and capacity_df['ì •ì› ì´ˆê³¼ ë°œìƒ ê±´ìˆ˜'].sum() == 0:
        print("ğŸ‰ ì„¸ë§ˆí¬ì–´ í•µì‹¬ ê¸°ëŠ¥ (ì •ì› ì´ˆê³¼ ë°©ì§€): ëª¨ë“  ë°©ì—ì„œ ì™„ë²½ ì„±ê³µ")
    elif len(capacity_df) > 0:
        print("âš ï¸ ì„¸ë§ˆí¬ì–´ í•µì‹¬ ê¸°ëŠ¥ (ì •ì› ì´ˆê³¼ ë°©ì§€): ì¼ë¶€ ë°©ì—ì„œ ê²€ì¦ ì‹¤íŒ¨")
    
    if len(sequential_df) > 0 and sequential_df['ìˆœì°¨ì  ì¼ê´€ì„± ì°¨ì´ ê±´ìˆ˜'].sum() > 0:
        print("ğŸ“ ìˆœì°¨ì  ì¼ê´€ì„±: ë¶€ë¶„ì  ë³´ì¥ íŠ¹ì„± ê´€ì°° (ì„¸ë§ˆí¬ì–´ ê³ ìœ  íŠ¹ì„±)")
    
    if len(concurrent_df) > 0 and concurrent_df['ë°œìƒ ê±´ìˆ˜'].sum() > 0:
        print("ğŸš€ ë™ì‹œì„± í™œìš©: CAS ê¸°ë°˜ íš¨ìœ¨ì  ë™ì‹œ ì‹¤í–‰ ê´€ì°° (ì˜ë„ëœ ì •ìƒ ë™ì‘)")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì„¸ë§ˆí¬ì–´ ë°©ë³„ í†µê³„ ë¶„ì„ê¸°")
    parser.add_argument('preprocessor_csv', help='ì„¸ë§ˆí¬ì–´ ì „ì²˜ë¦¬ ê²°ê³¼ CSV íŒŒì¼ (preprocessor_semaphore.csv)')
    parser.add_argument('analysis_csv', help='ì„¸ë§ˆí¬ì–´ ë¶„ì„ ê²°ê³¼ CSV íŒŒì¼ (semaphore_analysis_result.csv)')
    parser.add_argument('output_xlsx', help='ì„¸ë§ˆí¬ì–´ ë°©ë³„ í†µê³„ ë¶„ì„ Excel ì¶œë ¥ íŒŒì¼')
    parser.add_argument('--rooms', help='ë¶„ì„í•  ë°© ë²ˆí˜¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)')
    
    args = parser.parse_args()
    
    try:
        print("ğŸš€ ì„¸ë§ˆí¬ì–´ ë°©ë³„ í†µê³„ ë¶„ì„ê¸° ì‹œì‘...")
        print("ğŸ¯ ì„¸ë§ˆí¬ì–´ 3ê°€ì§€ ë°©ë³„ ë¶„ì„: ìˆœì°¨ì  ì¼ê´€ì„± ê´€ì°° + ë™ì‹œ ì‹¤í–‰ íŒ¨í„´ ê´€ì°° + ì •ì› ì´ˆê³¼ ë°©ì§€ ê²€ì¦")
        print(f"ì…ë ¥ íŒŒì¼ 1: {args.preprocessor_csv}")
        print(f"ì…ë ¥ íŒŒì¼ 2: {args.analysis_csv}")
        print(f"ì¶œë ¥ íŒŒì¼: {args.output_xlsx}")
        
        # 1. ì„¸ë§ˆí¬ì–´ ë°ì´í„° ë¡œë“œ ë° ê²€ì¦
        preprocessor_df, analysis_df = load_and_validate_semaphore_data(args.preprocessor_csv, args.analysis_csv)
        
        # 2. ë°© ë²ˆí˜¸ í•„í„°ë§ (ì„ íƒì‚¬í•­)
        if args.rooms:
            room_numbers = [int(room.strip()) for room in args.rooms.split(',')]
            preprocessor_df = preprocessor_df[preprocessor_df['roomNumber'].isin(room_numbers)]
            analysis_df = analysis_df[analysis_df['roomNumber'].isin(room_numbers)]
            print(f"ğŸ” ë°© ë²ˆí˜¸ {room_numbers}ë¡œ í•„í„°ë§ ì ìš©")
        
        # 3. ë°©ë³„ ì „ì²´ ìš”ì²­ìˆ˜ ì§‘ê³„
        total_requests_df = calculate_total_requests_per_room(preprocessor_df)
        
        # 4. ì„¸ë§ˆí¬ì–´ 3ê°€ì§€ ë°©ë³„ ë¶„ì„
        print("\n=== ğŸ¯ ì„¸ë§ˆí¬ì–´ 3ê°€ì§€ ë°©ë³„ ë¶„ì„ ì‹¤í–‰ ===")
        sequential_df = analyze_sequential_consistency_per_room(preprocessor_df, analysis_df, total_requests_df)
        concurrent_df = analyze_concurrent_execution_per_room(preprocessor_df, analysis_df, total_requests_df)
        capacity_df = analyze_capacity_prevention_per_room(preprocessor_df, analysis_df, total_requests_df)
        
        # 5. Excel íŒŒì¼ ìƒì„±
        create_excel_output(sequential_df, concurrent_df, capacity_df, args.output_xlsx)
        
        # 6. ìš”ì•½ í†µê³„ ì¶œë ¥
        print_summary_statistics(sequential_df, concurrent_df, capacity_df, total_requests_df)
        
        print("\nğŸ‰ ì„¸ë§ˆí¬ì–´ ë°©ë³„ í†µê³„ ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

if __name__ == '__main__':
    main()
import pandas as pd  # ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import re             # ì •ê·œ í‘œí˜„ì‹ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os             # ìš´ì˜ì²´ì œ ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import shutil         # íŒŒì¼ ë³µì‚¬/ì´ë™ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import argparse       # ëª…ë ¹ì¤„ ì¸ì ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from openpyxl import load_workbook  # Excel íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ìƒìˆ˜ ì •ì˜
LOG_FILE = 'ChatService.log'  # ê¸°ë³¸ ë¡œê·¸ íŒŒì¼ëª…
NEW_LOG_PATH = r'E:\devSpace\ChatServiceTest\log\ChatService.log'  # ìƒˆ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ

def replace_log_file():
    """
    ë¡œê·¸ íŒŒì¼ì„ ìƒˆë¡œìš´ ë²„ì „ìœ¼ë¡œ êµì²´í•˜ëŠ” í•¨ìˆ˜
    - ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
    - ìƒˆ ë¡œê·¸ íŒŒì¼ì„ ë³µì‚¬í•´ì„œ ê°€ì ¸ì˜´
    """
    # ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì‚­ì œ
    if os.path.exists(LOG_FILE):
        os.remove(LOG_FILE)
    
    # ìƒˆ ë¡œê·¸ íŒŒì¼ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
    shutil.copy(NEW_LOG_PATH, LOG_FILE)

def parse_logs(filepath, room_number=None):
    """
    ë¡œê·¸ íŒŒì¼ì„ íŒŒì‹±í•´ì„œ í•µì‹¬ ì´ë²¤íŠ¸ë“¤ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼:
    - ì§„ì§œ ì„ê³„êµ¬ì—­: PRE_JOIN_CURRENT_STATE ~ JOIN_SUCCESS_EXISTING
    - ê·œì¹™ 2 ê²½í•© íƒì§€: ì§„ì§œ ì„ê³„êµ¬ì—­ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
    
    ì…ë ¥:
    - filepath: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    - room_number: íŠ¹ì • ë°© ë²ˆí˜¸ë§Œ í•„í„°ë§ (Noneì´ë©´ ëª¨ë“  ë°©)
    
    ì¶œë ¥: DataFrame - íŒŒì‹±ëœ ì´ë²¤íŠ¸ ë°ì´í„°
    """
    
    # ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´ ì •ì˜
    # í•µì‹¬ ì´ë²¤íŠ¸ë“¤ë§Œ ì¶”ì¶œ (ìš”êµ¬ì‚¬í•­ ìˆ˜ì •ì— ë”°ë¼ INCREMENT ì´ë²¤íŠ¸ ë¶ˆí•„ìš”):
    # - PRE_JOIN_CURRENT_STATE: ì§„ì§œ ì„ê³„êµ¬ì—­ ì‹œì‘
    # - JOIN_SUCCESS_EXISTING: ì§„ì§œ ì„ê³„êµ¬ì—­ ë (ì„±ê³µ)
    # - JOIN_FAIL_OVER_CAPACITY_EXISTING: ì§„ì§œ ì„ê³„êµ¬ì—­ ë (ì‹¤íŒ¨)
    pattern = re.compile(
        r'timestampIso=(?P<timestamp>\S+).*?'  # ì‹œê°„ ì •ë³´ ì¶”ì¶œ
        r'event=(?P<event>PRE_JOIN_CURRENT_STATE|JOIN_SUCCESS_EXISTING|JOIN_FAIL_OVER_CAPACITY_EXISTING).*?'  # í•µì‹¬ ì´ë²¤íŠ¸ë§Œ
        r'roomNumber=(?P<roomNumber>\d+).*?'    # ë°© ë²ˆí˜¸
        r'userId=(?P<userId>\S+).*?'            # ì‚¬ìš©ì ID
        r'currentPeople=(?P<currentPeople>\d+).*?'  # í˜„ì¬ ì¸ì›ìˆ˜
        r'maxPeople=(?P<maxPeople>\d+)'         # ìµœëŒ€ ì •ì›
    )
    
    records = []  # íŒŒì‹±ëœ ë ˆì½”ë“œë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    
    # ë¡œê·¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ìœ¼ë©´ì„œ íŒŒì‹±
    with open(filepath, encoding='utf-8') as f:
        for line in f:
            # ì •ê·œì‹ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
            match = pattern.search(line)
            if match:
                # ë§¤ì¹­ëœ ê·¸ë£¹ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                data = match.groupdict()
                
                # ë¬¸ìì—´ë¡œ ì¶”ì¶œëœ ìˆ«ìë“¤ì„ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
                data['roomNumber'] = int(data['roomNumber'])
                data['currentPeople'] = int(data['currentPeople'])
                data['maxPeople'] = int(data['maxPeople'])
                
                # ğŸ”§ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ì •ë³´ ì¶”ì¶œ (ì§„ì§œ ì„ê³„êµ¬ì—­ ì •ë°€ë„ í–¥ìƒ)
                # ìš”êµ¬ì‚¬í•­ ìˆ˜ì •ìœ¼ë¡œ INCREMENT ì´ë²¤íŠ¸ëŠ” ë¶ˆí•„ìš”í•˜ì§€ë§Œ, 
                # ì§„ì§œ ì„ê³„êµ¬ì—­ì˜ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ëŠ” ì—¬ì „íˆ ìœ ìš©
                nano_match = re.search(r'nanoTime=(\d+)', line)
                epoch_match = re.search(r'epochNano=(\d+)', line)
                
                if nano_match:
                    data['nanoTime'] = int(nano_match.group(1))
                if epoch_match:
                    data['epochNano'] = int(epoch_match.group(1))
                
                # ë°© ë²ˆí˜¸ í•„í„°ë§ ì ìš©
                if room_number is None or data['roomNumber'] == room_number:
                    records.append(data)
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•´ì„œ ë°˜í™˜
    return pd.DataFrame(records)

def build_paired_data_true_critical_section(df):
    """
    ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ í˜ì–´ë§ ë¡œì§ í•¨ìˆ˜
    - ì§„ì§œ ì„ê³„êµ¬ì—­ ê¸°ì¤€: PRE_JOIN_CURRENT_STATE ~ JOIN_SUCCESS_EXISTING
    - ê·œì¹™ 2 ê²½í•© íƒì§€: ì§„ì§œ ì„ê³„êµ¬ì—­ ê²¹ì¹¨ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
    
    ì…ë ¥: df (DataFrame) - íŒŒì‹±ëœ ë¡œê·¸ ë°ì´í„°
    ì¶œë ¥: DataFrame - í˜ì–´ë§ëœ ì…ì¥ ìš”ì²­ ë°ì´í„°
    """
    
    # ë¹ˆ ë°ì´í„°ë©´ ë¹ˆ DataFrame ë°˜í™˜
    if df.empty:
        return pd.DataFrame()
    
    # === í•µì‹¬ ì´ë²¤íŠ¸ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬ ===
    pre = df[df['event'] == 'PRE_JOIN_CURRENT_STATE'].copy()          # ì§„ì§œ ì„ê³„êµ¬ì—­ ì‹œì‘
    success = df[df['event'] == 'JOIN_SUCCESS_EXISTING'].copy()       # ì§„ì§œ ì„ê³„êµ¬ì—­ ë (ì„±ê³µ)
    fail = df[df['event'] == 'JOIN_FAIL_OVER_CAPACITY_EXISTING'].copy() # ì§„ì§œ ì„ê³„êµ¬ì—­ ë (ì‹¤íŒ¨)

    # === í˜ì–´ë§ì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„± ===
    # ê°™ì€ ë°©, ê°™ì€ ì‚¬ìš©ìì˜ ì´ë²¤íŠ¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°í•˜ê¸° ìœ„í•œ ì¸ë±ìŠ¤
    for event_df in [pre, success, fail]:
        if not event_df.empty:
            # ë°© ë²ˆí˜¸ì™€ ì‚¬ìš©ì IDë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ìˆœì°¨ ë²ˆí˜¸ ë¶€ì—¬
            event_df['pair_idx'] = event_df.groupby(['roomNumber', 'userId']).cumcount()

    # === ì„±ê³µ ì¼€ì´ìŠ¤ í˜ì–´ë§ ===
    paired_success = pd.DataFrame()
    if not pre.empty and not success.empty:
        # roomNumber, userId, pair_idxê°€ ê°™ì€ ë ˆì½”ë“œë“¤ì„ ì—°ê²°
        paired_success = pd.merge(pre, success, on=['roomNumber', 'userId', 'pair_idx'], suffixes=('_pre', '_suc'))
        
        # ì„±ê³µ ì¼€ì´ìŠ¤ ê²°ê³¼ í•„ë“œ ìƒì„±
        paired_success['join_result'] = 'SUCCESS'
        paired_success['curr_people'] = paired_success['currentPeople_suc']
        paired_success['expected_people'] = paired_success['currentPeople_pre'] + 1

    # === ì‹¤íŒ¨ ì¼€ì´ìŠ¤ í˜ì–´ë§ ===
    paired_fail = pd.DataFrame()
    if not pre.empty and not fail.empty:
        # roomNumber, userId, pair_idxê°€ ê°™ì€ ë ˆì½”ë“œë“¤ì„ ì—°ê²°
        paired_fail = pd.merge(pre, fail, on=['roomNumber', 'userId', 'pair_idx'], suffixes=('_pre', '_fail'))
        
        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ê²°ê³¼ í•„ë“œ ìƒì„±
        paired_fail['join_result'] = 'FAIL_OVER_CAPACITY'
        paired_fail['curr_people'] = paired_fail['currentPeople_fail']
        paired_fail['expected_people'] = None  # ì‹¤íŒ¨í–ˆìœ¼ë¯€ë¡œ ì˜ˆìƒ ì¸ì›ìˆ˜ ì—†ìŒ

    # === ì„±ê³µê³¼ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ í†µí•© ===
    result = pd.concat([paired_success, paired_fail], ignore_index=True)
    
    if result.empty:
        return pd.DataFrame()
    
    # === ë°©ë³„ ì‹œê°„ ìˆœ ì •ë ¬ ë° ìˆœë²ˆ ë¶€ì—¬ ===
    result['timestamp_pre'] = pd.to_datetime(result['timestamp_pre'])
    result = result.sort_values(['roomNumber', 'timestamp_pre']).reset_index(drop=True)
    result['room_entry_sequence'] = result.groupby('roomNumber').cumcount() + 1
    
    # === ë¶„ì„ì„ ìœ„í•œ êµ¬ê°„ ìƒì„± ===
    result['bin'] = pd.cut(range(len(result)), bins=10, labels=range(1, 11))
    
    # === ğŸ”§ ìˆ˜ì •ëœ ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬ ===
    # ì›í•˜ëŠ” ìˆœì„œ: roomNumber, bin, user_id, prev_people, curr_people, expected_people, max_people, room_entry_sequence, join_result, prev_entry_time, curr_entry_time, true_critical_section_nanoTime_start, true_critical_section_epochNano_start, true_critical_section_nanoTime_end, true_critical_section_epochNano_end
    final_columns = {
        'roomNumber': 'roomNumber',
        'bin': 'bin',
        'userId': 'user_id',
        'currentPeople_pre': 'prev_people',
        'curr_people': 'curr_people',
        'expected_people': 'expected_people',
        'maxPeople_pre': 'max_people',
        'room_entry_sequence': 'room_entry_sequence',
        'join_result': 'join_result',
        'timestamp_pre': 'prev_entry_time'
    }
    
    # === ì‹œê°„ í•„ë“œ ì²˜ë¦¬ ===
    if 'timestamp_suc' in result.columns:
        final_columns['timestamp_suc'] = 'curr_entry_time'
    elif 'timestamp_fail' in result.columns:
        final_columns['timestamp_fail'] = 'curr_entry_time'
    
    # === ğŸ”§ ì§„ì§œ ì„ê³„êµ¬ì—­ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ í•„ë“œ ì¶”ê°€ ===
    # ì§„ì§œ ì„ê³„êµ¬ì—­ì˜ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ì‹œì‘ì 
    if 'nanoTime_pre' in result.columns:
        final_columns['nanoTime_pre'] = 'true_critical_section_nanoTime_start'
    if 'epochNano_pre' in result.columns:
        final_columns['epochNano_pre'] = 'true_critical_section_epochNano_start'
    
    # ì§„ì§œ ì„ê³„êµ¬ì—­ì˜ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ ëì 
    if 'nanoTime_suc' in result.columns:
        final_columns['nanoTime_suc'] = 'true_critical_section_nanoTime_end'
    elif 'nanoTime_fail' in result.columns:
        final_columns['nanoTime_fail'] = 'true_critical_section_nanoTime_end'
    
    if 'epochNano_suc' in result.columns:
        final_columns['epochNano_suc'] = 'true_critical_section_epochNano_end'
    elif 'epochNano_fail' in result.columns:
        final_columns['epochNano_fail'] = 'true_critical_section_epochNano_end'
    
    # === ìµœì¢… ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ë³€ê²½ ===
    # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒ
    existing_columns = {old: new for old, new in final_columns.items() if old in result.columns}
    
    # ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ì»¬ëŸ¼ ì •ë ¬
    desired_order = ['roomNumber', 'bin', 'user_id', 'prev_people', 'curr_people', 'expected_people', 'max_people', 
                     'room_entry_sequence', 'join_result', 'prev_entry_time', 'curr_entry_time',
                     'true_critical_section_nanoTime_start', 'true_critical_section_epochNano_start',
                     'true_critical_section_nanoTime_end', 'true_critical_section_epochNano_end']
    
    # DataFrame ì¬êµ¬ì„± (ì»¬ëŸ¼ëª… ë³€ê²½ í›„ ìˆœì„œ ì •ë ¬)
    result = result[list(existing_columns.keys())].rename(columns=existing_columns)
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ ì›í•˜ëŠ” ìˆœì„œë¡œ ì¬ë°°ì—´
    final_order = [col for col in desired_order if col in result.columns]
    result = result[final_order]
    
    return result

def get_true_critical_section_desc_table():
    """
    ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ ì„¤ëª… í…Œì´ë¸” ìƒì„± í•¨ìˆ˜
    - ì§„ì§œ ì„ê³„êµ¬ì—­ ê¸°ì¤€ í•„ë“œ ì„¤ëª…
    - ê·œì¹™ 2 ê²½í•© íƒì§€: ì§„ì§œ ì„ê³„êµ¬ì—­ ê²¹ì¹¨ ê¸°ì¤€
    """
    return [
        ["ì†ì„±ëª…", "ë¶„ì„ ëª©ì ", "ë„ì¶œ ë°©ë²•"],
        ["roomNumber", "ë°© ë²ˆí˜¸ ì‹ë³„", "ë¡œê·¸ í•„ë“œ: roomNumber"],
        ["bin", "ë¶„ì„ êµ¬ê°„ êµ¬ë¶„", "ì „ì²´ ë°ì´í„°ë¥¼ 10ë“±ë¶„"],
        ["user_id", "ì‚¬ìš©ì ì‹ë³„", "ë¡œê·¸ í•„ë“œ: userId"],
        ["prev_people", "ì…ì¥ ì „ ì¸ì›ìˆ˜", "PRE_JOIN_CURRENT_STATEì˜ currentPeople"],
        ["curr_people", "ì…ì¥ í›„ ì¸ì›ìˆ˜", "SUCCESS/FAIL ì´ë²¤íŠ¸ì˜ currentPeople"],
        ["expected_people", "ê¸°ëŒ€ ì¸ì›ìˆ˜", "prev_people + 1 (ì„±ê³µì‹œ)"],
        ["max_people", "ìµœëŒ€ ì •ì›", "ë¡œê·¸ í•„ë“œ: maxPeople"],
        ["room_entry_sequence", "ë°©ë³„ ì…ì¥ ìˆœë²ˆ", "prev_entry_time ê¸°ì¤€ ë°©ë³„ ìˆœë²ˆ"],
        ["join_result", "ì…ì¥ ê²°ê³¼", "SUCCESS ë˜ëŠ” FAIL_OVER_CAPACITY"],
        ["prev_entry_time", "ì§„ì§œ ì„ê³„êµ¬ì—­ ì‹œì‘", "PRE_JOIN_CURRENT_STATE íƒ€ì„ìŠ¤íƒ¬í”„"],
        ["curr_entry_time", "ì§„ì§œ ì„ê³„êµ¬ì—­ ë", "SUCCESS/FAIL íƒ€ì„ìŠ¤íƒ¬í”„"],
        ["true_critical_section_nanoTime_start", "ì§„ì§œ ì„ê³„êµ¬ì—­ ì‹œì‘ ë‚˜ë…¸ì´ˆ", "PRE_JOIN_CURRENT_STATEì˜ nanoTime"],
        ["true_critical_section_epochNano_start", "ì§„ì§œ ì„ê³„êµ¬ì—­ ì‹œì‘ Epoch ë‚˜ë…¸ì´ˆ", "PRE_JOIN_CURRENT_STATEì˜ epochNano"],
        ["true_critical_section_nanoTime_end", "ì§„ì§œ ì„ê³„êµ¬ì—­ ë ë‚˜ë…¸ì´ˆ", "SUCCESS/FAILì˜ nanoTime"],
        ["true_critical_section_epochNano_end", "ì§„ì§œ ì„ê³„êµ¬ì—­ ë Epoch ë‚˜ë…¸ì´ˆ", "SUCCESS/FAILì˜ epochNano"]
    ]

def save_with_side_table(df_result, out_xlsx, desc_table):
    """
    Excel íŒŒì¼ì— ë°ì´í„°ì™€ ì„¤ëª… í…Œì´ë¸”ì„ í•¨ê»˜ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    df_result.to_excel(out_xlsx, index=False)
    
    wb = load_workbook(out_xlsx)
    ws = wb.active
    
    start_col = len(df_result.columns) + 2
    
    for i, row in enumerate(desc_table):
        for j, val in enumerate(row):
            ws.cell(row=i + 1, column=start_col + j, value=val)
    
    wb.save(out_xlsx)

def analyze_results(df):
    """
    ì²˜ë¦¬ëœ ë°ì´í„°ì— ëŒ€í•œ ê°„ë‹¨í•œ í†µê³„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    if df.empty:
        print("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê¸°ë³¸ í†µê³„ ê³„ì‚°
    total_requests = len(df)
    success_count = len(df[df['join_result'] == 'SUCCESS'])
    fail_count = len(df[df['join_result'] == 'FAIL_OVER_CAPACITY'])
    
    print(f"\n=== ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ì „ì²˜ë¦¬ ê²°ê³¼ ===")
    print(f"ì „ì²´ ì…ì¥ ìš”ì²­ ìˆ˜: {total_requests}")
    print(f"ì„±ê³µ: {success_count}ê±´ ({success_count/total_requests*100:.1f}%)")
    print(f"ì‹¤íŒ¨: {fail_count}ê±´ ({fail_count/total_requests*100:.1f}%)")
    
    # ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ì˜ˆë¹„ ë¶„ì„
    if success_count > 0:
        valid_success = df[(df['join_result'] == 'SUCCESS') & df['expected_people'].notna()]
        if not valid_success.empty:
            race_conditions = valid_success[valid_success['curr_people'] != valid_success['expected_people']]
            race_count = len(race_conditions)
            print(f"ì ì¬ì  ë ˆì´ìŠ¤ ì»¨ë””ì…˜: {race_count}ê±´ ({race_count/success_count*100:.1f}%)")
    
    # ì§„ì§œ ì„ê³„êµ¬ì—­ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ í†µê³„
    if 'true_critical_section_nanoTime_start' in df.columns and 'true_critical_section_nanoTime_end' in df.columns:
        nano_start_count = df['true_critical_section_nanoTime_start'].notna().sum()
        nano_end_count = df['true_critical_section_nanoTime_end'].notna().sum()
        print(f"ì§„ì§œ ì„ê³„êµ¬ì—­ ë‚˜ë…¸ì´ˆ ì •ë°€ë„: ì‹œì‘ {nano_start_count}ê±´, ë {nano_end_count}ê±´")
    
    # ë°©ë³„ í†µê³„
    room_stats = df.groupby('roomNumber').agg({
        'user_id': 'count',
        'join_result': lambda x: (x == 'SUCCESS').sum()
    }).rename(columns={'user_id': 'total_requests', 'join_result': 'success_count'})
    
    print(f"\n=== ë°©ë³„ í†µê³„ ===")
    for room_num, stats in room_stats.iterrows():
        success_rate = stats['success_count'] / stats['total_requests'] * 100
        print(f"ë°© {room_num}: ì´ {stats['total_requests']}ê±´, ì„±ê³µ {stats['success_count']}ê±´ ({success_rate:.1f}%)")

def main():
    """
    ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ë©”ì¸ í•¨ìˆ˜
    """
    parser = argparse.ArgumentParser(description="Race Condition ì´ë²¤íŠ¸ ì „ì²˜ë¦¬ê¸° (ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜)")
    parser.add_argument('--room', type=int, help='íŠ¹ì • ë°© ë²ˆí˜¸ë§Œ ì²˜ë¦¬ (ì˜µì…˜)')
    parser.add_argument('--csv', type=str, help='ì¶”ê°€ CSV íŒŒì¼ëª… (ì˜µì…˜)')
    parser.add_argument('--xlsx', type=str, help='Excel íŒŒì¼ëª… (ì˜µì…˜)')
    
    args = parser.parse_args()
    
    try:
        print("ğŸ”§ ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ Race Condition ì´ë²¤íŠ¸ ì „ì²˜ë¦¬ê¸° ì‹œì‘...")
        print("ğŸ“‹ ê·œì¹™ 2 ê²½í•© íƒì§€: ì§„ì§œ ì„ê³„êµ¬ì—­ (PRE_JOIN_CURRENT_STATE ~ JOIN_SUCCESS_EXISTING) ê¸°ì¤€")
        
        # 1ë‹¨ê³„: ë¡œê·¸ íŒŒì¼ êµì²´
        print("1. ë¡œê·¸ íŒŒì¼ êµì²´ ì¤‘...")
        replace_log_file()
        
        # 2ë‹¨ê³„: ë¡œê·¸ íŒŒì‹± (ì§„ì§œ ì„ê³„êµ¬ì—­ ì´ë²¤íŠ¸)
        print("2. ì§„ì§œ ì„ê³„êµ¬ì—­ ì´ë²¤íŠ¸ íŒŒì‹± ì¤‘...")
        df = parse_logs(LOG_FILE, room_number=args.room)
        print(f"   íŒŒì‹±ëœ ì´ë²¤íŠ¸ ìˆ˜: {len(df)}")
        
        # 3ë‹¨ê³„: ì§„ì§œ ì„ê³„êµ¬ì—­ ê¸°ì¤€ í˜ì–´ë§
        print("3. ì§„ì§œ ì„ê³„êµ¬ì—­ ê¸°ì¤€ í˜ì–´ë§ ì²˜ë¦¬ ì¤‘...")
        result = build_paired_data_true_critical_section(df)
        print(f"   í˜ì–´ë§ëœ ìš”ì²­ ìˆ˜: {len(result)}")
        
        # 4ë‹¨ê³„: ê²°ê³¼ ì €ì¥
        print("4. ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ê¸°ë³¸ CSV íŒŒì¼ ì €ì¥
        if args.room:
            base_filename = f'racecondition_event_preprocessor_result_room{args.room}.csv'
        else:
            base_filename = 'racecondition_event_preprocessor_result.csv'
        
        result.to_csv(base_filename, index=False, encoding='utf-8-sig')
        print(f"   CSV ì €ì¥ ì™„ë£Œ: {base_filename}")
        
        # ì¶”ê°€ íŒŒì¼ ì €ì¥
        if args.csv:
            result.to_csv(args.csv, index=False, encoding='utf-8-sig')
            print(f"   ì¶”ê°€ CSV ì €ì¥ ì™„ë£Œ: {args.csv}")
        
        if args.xlsx:
            desc_table = get_true_critical_section_desc_table()
            save_with_side_table(result, args.xlsx, desc_table)
            print(f"   Excel ì €ì¥ ì™„ë£Œ: {args.xlsx}")
        
        # 5ë‹¨ê³„: ê²°ê³¼ ë¶„ì„
        print("5. ê²°ê³¼ ë¶„ì„ ì¤‘...")
        analyze_results(result)
        
        print("\nâœ… ìˆ˜ì •ëœ ìš”êµ¬ì‚¬í•­ ê¸°ë°˜ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("ğŸ¯ ì§„ì§œ ì„ê³„êµ¬ì—­ ë‚˜ë…¸ì´ˆ ì •ë°€ë„ í•„ë“œ ì¶”ê°€ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()